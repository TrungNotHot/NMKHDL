{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"529554fc1039eef87120a6eb78cb8d0f289f7339"},"source":["This notebook covers:\n","* Regex basics\n","* Web scraping with BeautifulSoup\n","Link tham khảo\n","link dưới đây:\n","1. https://www.w3schools.com/python/python_regex.asp\n","2. https://regex101.com/\n","3. https://regexlearn.com/learn/regex101\n","4. https://www.crummy.com/software/BeautifulSoup/bs4/doc/"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["? là tìm phần thích hợp ngắn nhất có thể chứ ko phải tìm lặp 0 hoặc 1 lần như trong w3school"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8587b847b721482289161fc591509eca68cf3315","collapsed":true,"trusted":false},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"10cd97bfa26f84442f0e32a26b01cf8b6c9169b4"},"source":["## Regular expressions"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"cf339878b60841ce5bc5491767b8753c04c377ab","trusted":true},"outputs":[],"source":["from IPython.display import Image"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"47bb40cbd660f2425e61e232bb1f7143707f9839"},"source":["I have talked about some basic regex functionality which is taken from this excellent post"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"537f565d77cec29e570c510b9d7ffbed2f0f9d01"},"source":["https://www.machinelearningplus.com/python/python-regex-tutorial-examples/"]},{"cell_type":"code","execution_count":1,"metadata":{"_uuid":"c026c0a1fb31784c477a81ab9d0555b522634e75","collapsed":true,"trusted":false},"outputs":[],"source":["import re"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"570239c59df6d2c245d5fbb5a26011e3ddb2c18e","collapsed":true,"trusted":true},"outputs":[],"source":["Image(\"../imgs/regex.png\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"b8dc504876b8d816d4fa7bbbd39443920a704f14"},"source":["A regex pattern is a special language used to represent generic text, numbers or symbols so it can be used to extract texts that conform to that pattern."]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"ad0db29e249dd9ffb03fa85dabe1e7a021c3b647"},"source":["Here the '\\s' matches any whitespace character. By adding a '+' notation at the end will make the pattern match at least 1 or more spaces. So, this pattern will match even tab '\\t' characters as well."]},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"7432d095972ee0c4d5c0823799459cfd1abf0a14","collapsed":true,"trusted":false},"outputs":[],"source":["regex = re.compile('\\s+')"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"bd9fd8c41a4125219b20a8b48176b61b1973de20"},"source":["**Splitting a string using regex**"]},{"cell_type":"code","execution_count":3,"metadata":{"_uuid":"da5783b46154ba18400b8452da89bbab1de7682c","collapsed":true,"trusted":false},"outputs":[],"source":["text = \"Hello World.   Regex is awesome\""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["'Hello World. Regex is awesome'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["\" \".join(text.split())"]},{"cell_type":"code","execution_count":5,"metadata":{"_uuid":"fa93b6c42156a7550438d8fe6e395f50436a61d8","trusted":false},"outputs":[{"data":{"text/plain":["['Hello', 'World.', 'Regex', 'is', 'awesome']"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["regex.split(text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"f44fdf9f491f748456037c3fcc75bba51a32cac6"},"source":["Another way but regex is generally the better one"]},{"cell_type":"code","execution_count":7,"metadata":{"_uuid":"184e8dadf759664c110333ce90a1c1ec2f4508e8","trusted":false},"outputs":[{"data":{"text/plain":["['Hello', 'World.', 'Regex', 'is', 'awesome']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["re.split('\\s+', text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"a01a271f7f843c4176bc5f9ef55dcf259e429d2a"},"source":["**re.findall**"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"bee96336be13efe4676c8ed9f5bd4056333a0e38"},"source":["the findall method extracts all occurrences of the pattern"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"c10a03e40f667741f023082276539aba57ce87bd"},"source":[" `'\\d'` is a regular expression which matches any digit"]},{"cell_type":"code","execution_count":8,"metadata":{"_uuid":"e545e0deec686e3867028f0b4ffe9bc0516e8b48","collapsed":true,"trusted":false},"outputs":[],"source":["text = \"101 howard street, 246 mcallister street\""]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"1a3fc378d262e747def16fc65c163687d58e5830","collapsed":true,"trusted":false},"outputs":[],"source":["regex_num = re.compile('\\d+')  #one or more digits"]},{"cell_type":"code","execution_count":13,"metadata":{"_uuid":"d922d09aa08dab31a0b5fe345b8c7f38e61c871e","trusted":false},"outputs":[{"data":{"text/plain":["['101', '246']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["regex_num.findall(text)"]},{"cell_type":"code","execution_count":14,"metadata":{"_uuid":"ae59445e48ed013be32b7c75e4ce0bfab6d0880c","trusted":false},"outputs":[{"data":{"text/plain":["['', ' howard street, ', ' mcallister street']"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["regex_num.split(text)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["['101', '246']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["re.findall('\\d+', text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"37a63ea8747b63f9d4dcb7dee6b8bc28b2be989d"},"source":["**re.search() vs re.match()**"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"07666b59e0f2486ad70a279f641c93f1268d9972"},"source":["`regex.search()` returns a particular match object that contains the starting and ending positions of the **first occurrence of the pattern**.\n","\n","Likewise, `regex.match()` also returns a match object. But the difference is, it requires the pattern to be present at the **beginning of the text itself**."]},{"cell_type":"code","execution_count":10,"metadata":{"_uuid":"000af117eb4cc58657df8dbd738ad8a12a4fd39d","collapsed":true,"trusted":false},"outputs":[],"source":["text2 = \"MAT 20567567576  Mathematics 189\""]},{"cell_type":"code","execution_count":16,"metadata":{"_uuid":"c1315a35cb1a9fce4a2fca8822f302196dfc0f1e","collapsed":true,"trusted":false},"outputs":[],"source":["m = regex_num.match(text2)\n","m"]},{"cell_type":"code","execution_count":17,"metadata":{"_uuid":"1c7435e9191c13d3ea4faf8bf1280c7c3d2101ce","trusted":false},"outputs":[{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'group'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13132\\2592475637.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"]}],"source":["m.group()"]},{"cell_type":"code","execution_count":18,"metadata":{"_uuid":"936d2fc8accc08632e11be2b3b7898fbcac60b1f","trusted":false},"outputs":[{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'start'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13132\\3729158017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#returns the index of the starting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'start'"]}],"source":["m.start()  #returns the index of the starting"]},{"cell_type":"code","execution_count":19,"metadata":{"_uuid":"1b7a53f156886dc875b1f1ba4f308f2f6347425b","collapsed":true,"trusted":false},"outputs":[{"data":{"text/plain":["<re.Match object; span=(4, 15), match='20567567576'>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["s = regex_num.search(text2)\n","s"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"2f0d615a4ce19f36abb842dcd21663e37a3d9fd6","trusted":false},"outputs":[],"source":["s.group()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"c7ccd41cc77c525e8ae5eaf63e8673e0af1a75b9"},"source":["**Substituting one text by another using `regex.sub()`**"]},{"cell_type":"code","execution_count":20,"metadata":{"_uuid":"bd54698c0eac18f68da6bbdcf3156318acc57689","collapsed":true,"trusted":false},"outputs":[],"source":["text = \"\"\"101   COM \\t  Computers\n","205   MAT \\t  Mathematics\n","189   ENG  \\t  English\"\"\""]},{"cell_type":"code","execution_count":21,"metadata":{"_uuid":"bf8e1047edc05e645a2c1d1b25f087403a76295c","collapsed":true,"trusted":false},"outputs":[],"source":["regex = re.compile('\\s+')"]},{"cell_type":"code","execution_count":22,"metadata":{"_uuid":"9fef5a9568aed119070b27d7adceefe7491f761d","trusted":false},"outputs":[{"data":{"text/plain":["'101 COM Computers 205 MAT Mathematics 189 ENG English'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["regex.sub(' ', text)  #it replaces the regular expression by ' '"]},{"cell_type":"code","execution_count":23,"metadata":{"_uuid":"ce5af2862542536ecfd77ff4bd2946256b3616cb","trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["101 COM Computers\n","205 MAT Mathematics\n","189 ENG English\n"]}],"source":["# get rid of all extra spaces except newline\n","regex = re.compile('((?!\\n)\\s+)')\n","print(regex.sub(' ', text))"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"87043e4df8463e672501cc0f58aa7e2fe9ec529d"},"source":["**combining regex pattern**"]},{"cell_type":"code","execution_count":26,"metadata":{"_uuid":"8fe182fbc250bdc8863817ca62a626a82d13aa2a","trusted":false},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# define the course text pattern groups and extract\n","course_pattern = '([0-9]+)\\s*([A-Z]{3})\\s*([A-Za-z]{4,})'\n","re.findall(course_pattern, text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"4d3038458e2dce9f1fe35e188764773fe9d35baf"},"source":["**greedy regex**"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"142d7dd8e5ab1214a3d06e91c95296937af308f8"},"source":["The default behavior of regular expressions is to be greedy. That means it tries to extract as much as possible until it conforms to a pattern even when a smaller part would have been syntactically sufficient."]},{"cell_type":"code","execution_count":33,"metadata":{"_uuid":"e4870f6a9c7d774811790af2309fac2d8aadba54","trusted":false},"outputs":[{"data":{"text/plain":["['< body>Regex Greedy Matching Example < /body>< /body>']"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["text = \"< body>Regex Greedy Matching Example < /body>< /body>\"\n","re.findall('<.*>', text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"e2738db5df307cde0f061c5f35b03e7683a1b82f"},"source":["it should have stopped at first > but it didn't. For extracting only the smaller portions:"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"537b2d90e9ede94123561b3b73435d91b2cae282"},"source":["Lazy matching, on the other hand, ‘takes as little as possible’. This can be effected by adding a `?` at the end of the pattern."]},{"cell_type":"code","execution_count":34,"metadata":{"_uuid":"f6b670ef79d7901dfde0fd98c64cf4d6a290ea48","trusted":false},"outputs":[{"data":{"text/plain":["['< body>', '< /body>', '< /body>']"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["re.findall('<.*?>', text)"]},{"cell_type":"code","execution_count":29,"metadata":{"_uuid":"00f8d96d129458da810b886e275e8b372a64bcbb","collapsed":true,"trusted":false},"outputs":[],"source":["s = re.search('<.*?>', text)  #getting only the first one"]},{"cell_type":"code","execution_count":30,"metadata":{"_uuid":"3524f83ab553275242b47ff7c80d9efcf102c4db","trusted":false},"outputs":[{"data":{"text/plain":["'< body>'"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["s.group()"]},{"cell_type":"code","execution_count":31,"metadata":{"_uuid":"675278d128fbf7dec7b272316d6dd308608fbcae","collapsed":true,"trusted":false},"outputs":[],"source":["text = '01, Jan 2015'"]},{"cell_type":"code","execution_count":32,"metadata":{"_uuid":"e13e268bc8c72299fdc78d3a4ffe2afcd4bc8e34","trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["['201']\n"]}],"source":["print(re.findall('\\d{3}', text))"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"99308052f50445899ecfef3d86737dc459dd7644"},"source":["**matching word boundaries**"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"1e96e43cfeaec6475e5163306f589ddfee470a24"},"source":["Word boundaries `\\b` are commonly used to detect and match the beginning or end of a word. That is, one side is a word character and the other side is whitespace and vice versa.\n","\n","For example, the regex \\btoy will match the ‘toy’ in ‘toy cat’ and not in ‘tolstoy’. In order to match the ‘toy’ in ‘tolstoy’, you should use toy\\b\n","\n","Can you come up with a regex that will match only the first ‘toy’ in ‘play toy broke toys’? (hint: \\b on both sides)\n","\n","Likewise, `\\B` will match any non-boundary.\n","\n","For example, \\Btoy\\B will match ‘toy’ surrounded by words on both sides, as in, ‘antoynet’."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f72bed4462e57db41e860fb74b9c034ef0885522","trusted":false},"outputs":[],"source":["re.findall(r'\\btoy\\b', 'play toy broke toys')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8ded6ca9cccbb390724ed2e515a93a09be700d05","trusted":false},"outputs":[],"source":["re.findall(r'\\btoy', 'play toy broke toys')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"2e464fb5be59c819a92cec2525055c2981a8d2b6","trusted":false},"outputs":[],"source":["re.findall(r'toy\\b', 'play toy broke toys')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"65157a29d9124ea4118af3f24313744928c4aaa3","trusted":false},"outputs":[],"source":["re.findall(r'\\Btoy\\b', 'playtoy broke toys')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4e33eb2c05cce0d7c5a869acd9c80c3d2b1a4349","trusted":false},"outputs":[],"source":["re.findall(r'\\Btoy\\B', 'playtoybroke toys')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"cf4f08f4741a20e6b7f43ae2b0f93440e1b9e842","trusted":false},"outputs":[],"source":["re.findall(r'\\btoy', 'playtoybroke toys')"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"7d0b8c845660977871b8f2b7e0abfe1023dbe773"},"source":["**Practice regex examples**"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"199f74520e95b660a6d3323bf2b45146013cb1ac","collapsed":true,"trusted":false},"outputs":[],"source":["emails = \"\"\"zuck26@facebook.com\n","page33@google.com\n","jeff42@amazon.com\"\"\"\n","\n","desired_output = [('zuck26', 'facebook', 'com'), ('page33', 'google', 'com'),\n","                  ('jeff42', 'amazon', 'com')]"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6518108745df7697ac907fe7f218cb44cf1e7b78","collapsed":true,"trusted":false},"outputs":[],"source":["regex = re.compile('([\\w]+)@([\\w]+).([\\w]+)')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"7abc539508806923bbfc22b953099e849c92c55e","trusted":false},"outputs":[],"source":["regex.findall(emails)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"17cd6968a3384e66c6c318f978f3fef8bd79fa6e"},"source":["2. Retrieve all the words starting with ‘b’ or ‘B’ from the following text."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"452f6dfed9a2194ad5b0680363cc587b35e86c19","collapsed":true,"trusted":false},"outputs":[],"source":["text = \"\"\"Betty bought a bit of butter, \n","But the butter was so bitter, So she bought\n","some better butter, To make the bitter butter better.\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"92850ccf1845a30e958bdd6929d59569d8af2738","collapsed":true,"trusted":false},"outputs":[],"source":["regex = re.compile('([$bB]\\w+)')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"5c3da9b9214e8a2b607155936089fdb1080c81d0","trusted":false},"outputs":[],"source":["regex.findall(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"9cd8b2cd6df3300ff47653822e4ae34805cf7bac","collapsed":true,"trusted":false},"outputs":[],"source":["sentence = \"\"\"A, very   very; irregular_sentence\"\"\"\n","desired_output = \"A very very irregular sentence\""]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8cb82c7c0f30abcc40f04767390f170abb3f8f50","collapsed":true,"trusted":false},"outputs":[],"source":["regex = re.compile('[,\\s;_]+')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b08fa1c94763b29c9d5c2462989f3928739dc4f8","trusted":false},"outputs":[],"source":["' '.join(regex.split(sentence))"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f9d06204f9fbfa793bdf341760bb80e14e47ba1c","collapsed":true,"trusted":false},"outputs":[],"source":["tweet = '''Good advice! RT @TheNextWeb: What I would do differently if I was learning to code today http://t.co/lbwej0pxOd cc: @garybernhardt #rstats'''"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"43e5e0cd9cb9bb9eb0c5cdb6959904e0c3c1259a","collapsed":true,"trusted":false},"outputs":[],"source":["desired_output = 'Good advice What I would do differently if I was learning to code today'"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"86a67db9d560a83385d09a288f8b7c588097ae13","trusted":false},"outputs":[],"source":["def clean_tweet(tweet):\n","    tweet = re.sub('http\\S+\\s*', '', tweet)  # remove URLs\n","    tweet = re.sub('RT|cc', '', tweet)  # remove RT and cc\n","    tweet = re.sub('#\\S+', '', tweet)  # remove hashtags\n","    tweet = re.sub('@\\S+', '', tweet)  # remove mentions\n","    tweet = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"),\n","                   '', tweet)  # remove punctuations\n","    tweet = re.sub('\\s+', ' ', tweet)  # remove extra whitespace\n","    return tweet\n","\n","\n","print(clean_tweet(tweet))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Web Scraping with BeautifulSoup"]},{"cell_type":"code","execution_count":35,"metadata":{"_uuid":"706166c8c2d8ac42e917e833d01108b73b9c198f","collapsed":true,"trusted":false},"outputs":[],"source":["from bs4 import BeautifulSoup\n","import urllib.request\n","import requests"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["def download_html(url):\n","    with urllib.request.urlopen(url) as response:\n","        html = response.read()\n","        html = html.decode('utf-8')\n","    response.close()\n","    return html"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["url = 'https://www.imdb.com/search/title?release_date=2018&sort=boxoffice_gross_us,desc&start=1'\n","html = download_html(url)\n","\n","soup = BeautifulSoup(html, 'lxml') #html.parser"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Since above code extracts all data on the first page, below code is run only to extract movie information on it."]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["movie_blocks = soup.findAll('div',  {'class':'lister-item-content'})"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["<div class=\"lister-item-content\">\n","<h3 class=\"lister-item-header\">\n","<span class=\"lister-item-index unbold text-primary\">1.</span>\n","<a href=\"/title/tt1825683/\">Chiến Binh Báo Đen</a>\n","<span class=\"lister-item-year text-muted unbold\">(2018)</span>\n","</h3>\n","<p class=\"text-muted\">\n","<span class=\"certificate\">C16</span>\n","<span class=\"ghost\">|</span>\n","<span class=\"runtime\">134 min</span>\n","<span class=\"ghost\">|</span>\n","<span class=\"genre\">\n","Action, Adventure, Sci-Fi            </span>\n","</p>\n","<div class=\"ratings-bar\">\n","<div class=\"inline-block ratings-imdb-rating\" data-value=\"7.3\" name=\"ir\">\n","<span class=\"global-sprite rating-star imdb-rating\"></span>\n","<strong>7.3</strong>\n","</div>\n","<div class=\"inline-block ratings-user-rating\">\n","<span class=\"userRatingValue\" data-tconst=\"tt1825683\" id=\"urv_tt1825683\">\n","<span class=\"global-sprite rating-star no-rating\"></span>\n","<span class=\"rate\" data-no-rating=\"Rate this\" data-value=\"0\" name=\"ur\">Rate this</span>\n","</span>\n","<div class=\"starBarWidget\" id=\"sb_tt1825683\">\n","<div class=\"rating rating-list\" data-csrf-token=\"\" data-ga-identifier=\"\" data-starbar-class=\"rating-list\" data-user=\"\" id=\"tt1825683|imdb|7.3|7.3|adv_li_tt||advsearch|title\" itemprop=\"aggregateRating\" itemscope=\"\" itemtype=\"http://schema.org/AggregateRating\" title=\"Users rated this 7.3/10 (801,290 votes) - click stars to rate\">\n","<meta content=\"7.3\" itemprop=\"ratingValue\"/>\n","<meta content=\"10\" itemprop=\"bestRating\"/>\n","<meta content=\"801290\" itemprop=\"ratingCount\"/>\n","<span class=\"rating-bg\"> </span>\n","<span class=\"rating-imdb\" style=\"width: 102.2px\"> </span>\n","<span class=\"rating-stars\">\n","<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>1</span></a>\n","<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>2</span></a>\n","<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>3</span></a>\n","<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>4</span></a>\n","<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>5</span></a>\n","<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>6</span></a>\n","<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>7</span></a>\n","<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>8</span></a>\n","<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>9</span></a>\n","<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>10</span></a>\n","</span>\n","<span class=\"rating-rating\"><span class=\"value\">7.3</span><span class=\"grey\">/</span><span class=\"grey\">10</span></span>\n","<span class=\"rating-cancel\"><a href=\"/title/tt1825683/vote\" rel=\"nofollow\" title=\"Delete\"><span>X</span></a></span>\n"," </div>\n","</div>\n","</div>\n","<div class=\"inline-block ratings-metascore\">\n","<span class=\"metascore favorable\">88        </span>\n","        Metascore\n","            </div>\n","</div>\n","<p class=\"text-muted\">\n","T'Challa, heir to the hidden but advanced kingdom of Wakanda, must step forward to lead his people into a new future and must confront a challenger from his country's past.</p>\n","<p class=\"\">\n","    Director:\n","<a href=\"/name/nm3363032/\">Ryan Coogler</a>\n","<span class=\"ghost\">|</span> \n","    Stars:\n","<a href=\"/name/nm1569276/\">Chadwick Boseman</a>, \n","<a href=\"/name/nm0430107/\">Michael B. Jordan</a>, \n","<a href=\"/name/nm2143282/\">Lupita Nyong'o</a>, \n","<a href=\"/name/nm1775091/\">Danai Gurira</a>\n","</p>\n","<p class=\"sort-num_votes-visible\">\n","<span class=\"text-muted\">Votes:</span>\n","<span data-value=\"801290\" name=\"nv\">801,290</span>\n","<span class=\"ghost\">|</span> <span class=\"text-muted\">Gross:</span>\n","<span data-value=\"700,059,566\" name=\"nv\">$700.06M</span>\n","</p>\n","</div>"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["movie_blocks[0]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["BeautifulSoup.find_all(arguments) returns a list of BeautifulSoup objects. These are all occurrences matching the arguments. If there are no matches, method returns empty list. This is obviously used, when you cannot identify it right away and have to do some more digging before you get to the data you want.\n","\n","> Let's examine one of the extracted block to identify the elements that we need to scrape."]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["['(2018)']"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["movie_blocks[0].find('span', {'class': 'lister-item-year'}).contents"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/plain":["'2018'"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["import re\n","year = re.compile(\"\\d+\")\n","year.search(movie_blocks[0].find('span',{'class': 'lister-item-year'}).contents[0]).group()"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Movie Name: Chiến Binh Báo Đen \n","Release Year: 2018 \n","IMDb Rating: 7.3 \n","Meta score: 88.0 \n","Votes: 801,290\n"]}],"source":["mname = movie_blocks[0].find('a').get_text() # Name of the movie\n","\n","m_reyear = int(movie_blocks[0].find('span',{'class': 'lister-item-year'}).contents[0][1:-1]) # Release year\n","\n","m_rating = float(movie_blocks[0].find('div',{'class':'inline-block ratings-imdb-rating'}).get('data-value')) #rating\n","\n","m_mscore = float(movie_blocks[0].find('span',{'class':'metascore favorable'}).contents[0].strip()) #meta score\n","\n","m_votes = int(movie_blocks[0].find('span',{'name':'nv'}).get('data-value')) # votes\n","\n","print(\"Movie Name: \" + mname,\n","      \"\\nRelease Year: \" + str(m_reyear),\n","      \"\\nIMDb Rating: \" + str(m_rating),\n","      \"\\nMeta score: \" + str(m_mscore),\n","      \"\\nVotes: \" + '{:,}'.format(m_votes)\n","\n",")"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["def scrape_mblock(movie_block):\n","    \n","    movieb_data ={}\n","  \n","    try:\n","        movieb_data['name'] = movie_block.find('a').get_text() # Name of the movie\n","    except:\n","        movieb_data['name'] = None\n","\n","    try:    \n","        movieb_data['year'] = str(movie_block.find('span',{'class': 'lister-item-year'}).contents[0][1:-1]) # Release year\n","    except:\n","        movieb_data['year'] = None\n","\n","    try:\n","        movieb_data['rating'] = float(movie_block.find('div',{'class':'inline-block ratings-imdb-rating'}).get('data-value')) #rating\n","    except:\n","        movieb_data['rating'] = None\n","    \n","    try:\n","        movieb_data['m_score'] = float(movie_block.find('span',{'class':'metascore favorable'}).contents[0].strip()) #meta score\n","    except:\n","        movieb_data['m_score'] = None\n","\n","    try:\n","        movieb_data['votes'] = int(movie_block.find('span',{'name':'nv'}).get('data-value')) # votes\n","    except:\n","        movieb_data['votes'] = None\n","\n","    return movieb_data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> Then I create the below function to scrape all movie blocks within a single search result page"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["def scrape_m_page(movie_blocks):\n","    \n","    page_movie_data = []\n","    num_blocks = len(movie_blocks)\n","    \n","    for block in range(num_blocks):\n","        page_movie_data.append(scrape_mblock(movie_blocks[block]))\n","    \n","    return page_movie_data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> Now we built functions to extract all movie data from a single page.\n","\n","Next function will be created to iterate the above made function through all pages of the search result untill we scrape data for the targeted number of movies"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["import time     \n","import random as ran\n","def scrape_this(link,t_count):\n","    \n","    #from IPython.core.debugger import set_trace\n","\n","    base_url = link\n","    target = t_count\n","    \n","    current_mcount_start = 0\n","    current_mcount_end = 0\n","    remaining_mcount = target - current_mcount_end \n","    \n","    new_page_number = 1\n","    \n","    movie_data = []\n","    \n","    \n","    while remaining_mcount > 0:\n","\n","        url = base_url + str(new_page_number)\n","        \n","        #set_trace()\n","        \n","        source = download_html(url)\n","        soup = BeautifulSoup(source, 'html.parser') # lxml\n","        \n","        movie_blocks = soup.findAll('div',{'class':'lister-item-content'})\n","        \n","        movie_data.extend(scrape_m_page(movie_blocks))   \n","        \n","        current_mcount_start = int(soup.find(\"div\", {\"class\":\"nav\"}).find(\"div\", {\"class\": \"desc\"}).contents[1].get_text().split(\"-\")[0])\n","\n","        current_mcount_end = int(soup.find(\"div\", {\"class\":\"nav\"}).find(\"div\", {\"class\": \"desc\"}).contents[1].get_text().split(\"-\")[1].split(\" \")[0])\n","\n","        remaining_mcount = target - current_mcount_end\n","        \n","        print('\\r' + \"currently scraping movies from: \" + str(current_mcount_start) + \" - \"+str(current_mcount_end), \"| remaining count: \" + str(remaining_mcount), flush=True, end =\"\")\n","        \n","        new_page_number = current_mcount_end + 1\n","        \n","        time.sleep(ran.randint(0, 10))\n","    \n","    return movie_data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> Finally, we have put together all functions created above to scrape the top 150 movies on the list"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["List of top 150 movies:es from: 101 - 150 | remaining count: 0\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>year</th>\n","      <th>rating</th>\n","      <th>m_score</th>\n","      <th>votes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Chiến Binh Báo Đen</td>\n","      <td>2018</td>\n","      <td>7.3</td>\n","      <td>88.0</td>\n","      <td>801290</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Avengers: Cuộc Chiến Vô Cực</td>\n","      <td>2018</td>\n","      <td>8.4</td>\n","      <td>68.0</td>\n","      <td>1121664</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Gia Đình Siêu Nhân 2</td>\n","      <td>2018</td>\n","      <td>7.6</td>\n","      <td>80.0</td>\n","      <td>309100</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Thế Giới Khủng Long: Vương Quốc Sụp Đổ</td>\n","      <td>2018</td>\n","      <td>6.1</td>\n","      <td>NaN</td>\n","      <td>327060</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Aquaman: Đế Vương Atlantis</td>\n","      <td>2018</td>\n","      <td>6.8</td>\n","      <td>NaN</td>\n","      <td>490724</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>Boy Erased</td>\n","      <td>2018</td>\n","      <td>6.9</td>\n","      <td>69.0</td>\n","      <td>40286</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>Khách Sạn Tội Phạm</td>\n","      <td>2018</td>\n","      <td>6.1</td>\n","      <td>NaN</td>\n","      <td>55576</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>A-X-L Chú Chó Robot</td>\n","      <td>2018</td>\n","      <td>5.3</td>\n","      <td>NaN</td>\n","      <td>12545</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>Run the Race</td>\n","      <td>2018</td>\n","      <td>5.9</td>\n","      <td>NaN</td>\n","      <td>1620</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>Fahrenheit 11/9</td>\n","      <td>2018</td>\n","      <td>7.1</td>\n","      <td>69.0</td>\n","      <td>19928</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 5 columns</p>\n","</div>"],"text/plain":["                                       name  year  rating  m_score    votes\n","0                        Chiến Binh Báo Đen  2018     7.3     88.0   801290\n","1               Avengers: Cuộc Chiến Vô Cực  2018     8.4     68.0  1121664\n","2                      Gia Đình Siêu Nhân 2  2018     7.6     80.0   309100\n","3    Thế Giới Khủng Long: Vương Quốc Sụp Đổ  2018     6.1      NaN   327060\n","4                Aquaman: Đế Vương Atlantis  2018     6.8      NaN   490724\n","..                                      ...   ...     ...      ...      ...\n","145                              Boy Erased  2018     6.9     69.0    40286\n","146                      Khách Sạn Tội Phạm  2018     6.1      NaN    55576\n","147                     A-X-L Chú Chó Robot  2018     5.3      NaN    12545\n","148                            Run the Race  2018     5.9      NaN     1620\n","149                         Fahrenheit 11/9  2018     7.1     69.0    19928\n","\n","[150 rows x 5 columns]"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd \n","base_scraping_link = \"https://www.imdb.com/search/title?release_date=2018-01-01,2018-12-31&sort=boxoffice_gross_us,desc&start=\"\n","\n","top_movies = 150 #input(\"How many movies do you want to scrape?\")\n","films = []\n","\n","movies = scrape_this(base_scraping_link,int(top_movies))\n","\n","print('\\r'+\"List of top \" + str(top_movies) +\" movies:\" + \"\\n\", end=\"\\n\")\n","movies=pd.DataFrame(movies)\n","movies"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["movies.to_csv('../datasets/movies.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"toc":{"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"toc_cell":true,"toc_position":{},"toc_section_display":"none","toc_window_display":false}},"nbformat":4,"nbformat_minor":1}
