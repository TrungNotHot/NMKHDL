{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "                                                            Introduction to Data Science\n",
    "\n",
    "                                                            Programming Exercise: 04\n",
    "\n",
    "                                                            Name: Tran Duc Trung\n",
    "\n",
    "                                                            Student ID: 21280115\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 1.Trích xuất tất cả các định dạng ngày tháng năm có trong văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"5.txt\",\"r\")\n",
    "text=file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ngày 21 tháng 02 năm 2023',\n",
       " 'ngày 15 tháng 11 năm 2010',\n",
       " 'ngày 25 tháng 11 năm 2019',\n",
       " 'ngày 14 tháng 12 năm 2004',\n",
       " 'ngày 19 tháng 02 năm 2013',\n",
       " 'ngày 14 tháng 12 năm 2004',\n",
       " 'ngày 16 tháng 01 năm 2023',\n",
       " 'ngày 25 tháng 9 năm 2020',\n",
       " 'ngày 14 tháng 12 năm 2004',\n",
       " 'ngày 25 tháng 5 năm 2007',\n",
       " 'ngày 02 tháng 6 năm 1993',\n",
       " 'ngày 03 tháng 11 năm 2004',\n",
       " 'ngày 10 tháng 8 năm 2005',\n",
       " 'ngày 10 tháng 4 năm 2023']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_m_y=re.findall(r\"ngày \\d{1,2} tháng \\d{1,2} năm \\d{0,4}\",text)\n",
    "d_m_y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 2.Split văn bản thành danh sách các điều luật."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Điều 1. Phạm vi điều chỉnh và đối tượng áp dụng\n",
      "1. Thông tư này quy định mã số, tiêu chuẩn chức danh nghề nghiệp và xếp lương viên chức chuyên ngành tuyên truyền viên văn hóa.\n",
      "2. Thông tư này áp dụng đối với viên chức tuyên truyền viên văn hóa làm việc trong các đơn vị sự nghiệp công lập và các tổ chức, cá nhân có liên quan.\n",
      "Điều 2. Mã số các chức danh nghề nghiệp viên chức chuyên ngành tuyên truyền viên văn hóa\n",
      "1. Tuyên truyền viên văn hóa chính Mã số: V.10.10.34\n",
      "2. Tuyên truyền viên văn hóa Mã số: V.10.10.35\n",
      "3. Tuyên truyền viên văn hóa trung cấp Mã số: V.10.10.36\n",
      "Điều 3. Tiêu chuẩn về đạo đức nghề nghiệp của viên chức chuyên ngành tuyên truyền viên văn hóa\n",
      "1. Có trách nhiệm với công việc được giao, tuân thủ các quy định của pháp luật; thực hiện đúng và đầy đủ nghĩa vụ của viên chức trong hoạt động nghề nghiệp.\n",
      "2. Tâm huyết với nghề, trung thực, khách quan, thẳng thắn; làm việc khoa học, có chính kiến rõ ràng; có thái độ khiêm tốn, đúng mực khi tiếp xúc với nhân dân; có ý thức đấu tranh với những hành vi sai trái, tiêu cực; thực hành tiết kiệm, chống lãng phí.\n",
      "3. Có tinh thần đoàn kết, tích cực, chủ động phối hợp với đồng nghiệp thực hiện nhiệm vụ được giao.\n",
      "4. Không ngừng học tập, rèn luyện nâng cao phẩm chất, trình độ, năng lực.\n",
      "Điều 4. Tuyên truyền viên văn hóa chính - Mã số: V.10.10.34\n",
      "1. Nhiệm vụ:\n",
      "a) Chủ trì xây dựng kế hoạch hoạt động dài hạn, trung hạn, hàng năm về hoạt động tuyên truyền của đơn vị và tổ chức thực hiện sau khi được phê duyệt;\n",
      "b) Chủ trì biên soạn tài liệu và trực tiếp hướng dẫn nghiệp vụ hoạt động tuyên truyền cho cơ sở;\n",
      "c) Chủ trì tổ chức và thực hiện biên tập nội dung chương trình tuyên truyền phục vụ nhiệm vụ chính trị, kinh tế, văn hóa, xã hội; các phong trào, các cuộc vận động lớn; các ngày lễ, kỉ niệm lớn của địa phương và đất nước;\n",
      "d) Tổ chức biên soạn, biên tập các thể loại tin tức, tài liệu tuyên truyền; sáng tác, dàn dựng chương trình, tiết mục văn nghệ, tuyên truyền lưu động; thiết kế, dàn dựng triển lãm, cổ động trực quan;\n",
      "đ) Tham gia các hoạt động đào tạo, bồi dưỡng, hướng dẫn chuyên môn, nghiệp vụ hoạt động tuyên truyền.\n",
      "2. Tiêu chuẩn về trình độ đào tạo, bồi dưỡng:\n",
      "a) Có bằng tốt nghiệp đại học trở lên phù hợp với chuyên ngành tuyên truyền viên văn hóa;\n",
      "b) Có chứng chỉ bồi dưỡng tiêu chuẩn chức danh nghề nghiệp tuyên truyền viên văn hóa.\n",
      "3. Tiêu chuẩn về năng lực chuyên môn, nghiệp vụ:\n",
      "a) Nắm vững chủ trương, đường lối của Đảng, chính sách, pháp luật của Nhà nước về hoạt động tuyên truyền;\n",
      "b) Nắm vững phương pháp tổ chức, hình thức hoạt động tuyên truyền;\n",
      "c) Nắm vững lịch sử, văn hóa, xã hội trên địa bàn được phân công quản lý;\n",
      "d) Có chuyên môn về lĩnh vực văn hóa, nghệ thuật; am hiểu kiến thức, kỹ năng nghiệp vụ tuyên truyền;\n",
      "đ) Có năng lực thu thập, phân tích, tổng hợp và đề xuất các giải pháp để nâng cao chất lượng công tác tuyên truyền ;\n",
      "e) Có kỹ năng sử dụng công nghệ thông tin cơ bản, sử dụng được ngoại ngữ hoặc sử dụng được tiếng dân tộc thiểu số đối với viên chức công tác ở vùng dân tộc thiểu số theo yêu cầu vị trí việc làm.\n",
      "4. Yêu cầu đối với viên chức dự thi hoặc xét thăng hạng chức danh nghề nghiệp tuyên truyền viên văn hóa chính:\n",
      "Có thời gian công tác giữ chức danh nghề nghiệp tuyên truyền viên văn hóa hoặc tương đương từ đủ 09 năm trở lên (không kể thời gian tập sự, thử việc). Trường hợp có thời gian tương đương thì phải có ít nhất 01 năm (đủ 12 tháng) đang giữ chức danh nghề nghiệp tuyên truyền viên văn hóa tính đến ngày hết thời hạn nộp hồ sơ đăng ký dự thi hoặc xét thăng hạng.\n",
      "Điều 5. Tuyên truyền viên văn hóa - Mã số: V.10.10.35\n",
      "1. Nhiệm vụ:\n",
      "a) Xây dựng kế hoạch hàng năm về công tác tuyên truyền được giao và tổ chức thực hiện sau khi được phê duyệt;\n",
      "b) Trực tiếp biên soạn, thiết kế, trình bày các thể loại tin tức, tài liệu tuyên truyền; thực hiện tuyên truyền bằng tin tức, lời nói trực tiếp, thuyết minh, thuyết trình theo đề cương biên tập đã được duyệt;\n",
      "c) Tham gia tổ chức, dàn dựng chương trình, tiết mục văn nghệ, tuyên truyền lưu động; trực tiếp biểu diễn các tiết mục văn nghệ phục vụ nhiệm vụ chính trị;\n",
      "d) Tham gia thiết kế, dàn dựng các triển lãm, cổ động trực quan tại chỗ và lưu động; trực tiếp xây dựng đề cương tổng quát, đề cương chi tiết, biên tập, chú thích hình ảnh theo chủ đề, viết bài, thuyết minh nội dung triển lãm tại chỗ và lưu động.\n",
      "2. Tiêu chuẩn về trình độ đào tạo, bồi dưỡng:\n",
      "a) Có bằng tốt nghiệp đại học trở lên phù hợp với chuyên ngành tuyên truyền viên văn hóa;\n",
      "b) Có chứng chỉ bồi dưỡng tiêu chuẩn chức danh nghề nghiệp tuyên truyền viên văn hóa.\n",
      "3. Tiêu chuẩn về năng lực chuyên môn, nghiệp vụ:\n",
      "a) Nắm vững chủ trương, đường lối của Đảng, chính sách, pháp luật của Nhà nước về hoạt động tuyên truyền;\n",
      "b) Nắm được phương pháp tổ chức, hình thức hoạt động tuyên truyền;\n",
      "c) Có hiểu biết về lịch sử, văn hóa, xã hội trên địa bàn được phân công quản lý;\n",
      "d) Có kiến thức về lĩnh vực văn hóa, nghệ thuật; có một trong các kỹ năng: Thuyết minh, thuyết trình, biểu diễn nhạc cụ, biểu diễn văn nghệ, hội họa, thiết kế, thi công cổ động trực quan hoặc các kỹ năng nghiệp vụ khác phù hợp với hình thức tuyên truyền;\n",
      "đ) Sử dụng thành thạo các phương tiện, thiết bị kỹ thuật phục vụ yêu cầu nhiệm vụ;\n",
      "e) Có kỹ năng sử dụng công nghệ thông tin cơ bản, sử dụng được ngoại ngữ hoặc sử dụng được tiếng dân tộc thiểu số đối với viên chức công tác ở vùng dân tộc thiểu số theo yêu cầu vị trí việc làm.\n",
      "4. Yêu cầu đối với viên chức dự thi hoặc xét thăng hạng chức danh nghề nghiệp tuyên truyền viên văn hóa:\n",
      "Có thời gian công tác giữ chức danh nghề nghiệp tuyên truyền viên văn hoá trung cấp hoặc tương đương từ đủ 03 năm trở lên (không kể thời gian tập sự, thử việc). Trường hợp có thời gian tương đương thì phải có ít nhất 01 năm (đủ 12 tháng) đang giữ chức danh tuyên truyền viên văn hoá trung cấp tính đến ngày hết hạn nộp hồ sơ đăng ký dự thi hoặc xét thăng hạng.\n",
      "Điều 6. Tuyên truyền viên văn hóa trung cấp - Mã số: V.10.10.36\n",
      "1. Nhiệm vụ:\n",
      "a) Trực tiếp tham gia thực hiện tổ chức, biểu diễn các hoạt động tuyên truyền lưu động, hoạt động văn hóa, văn nghệ và các hình thức tuyên truyền cổ động khác tại chỗ hoặc lưu động phù hợp với nhiệm vụ được giao;\n",
      "b) Chụp ảnh, quay phim, thực hiện audio làm tư liệu phục vụ nội dung tuyên truyền.\n",
      "2. Tiêu chuẩn về trình độ đào tạo, bồi dưỡng:\n",
      "a) Có bằng tốt nghiệp trung cấp trở lên phù hợp với chuyên ngành tuyên truyền viên văn hóa;\n",
      "b) Có chứng chỉ bồi dưỡng tiêu chuẩn chức danh nghề nghiệp tuyên truyền viên văn hóa.\n",
      "3. Tiêu chuẩn về năng lực chuyên môn, nghiệp vụ:\n",
      "a) Nắm được chủ trương, đường lối của Đảng, chính sách, pháp luật của Nhà nước về hoạt động tuyên truyền;\n",
      "b) Có kiến thức cơ bản về công tác tuyên truyền và các bộ môn văn hóa nghệ thuật liên quan; có một trong các kỹ năng: Thuyết minh, thuyết trình, biểu diễn nhạc cụ, biểu diễn văn nghệ, hội họa, thiết kế, thi công cổ động trực quan hoặc các kỹ năng nghiệp vụ khác phù hợp với hình thức tuyên truyền;\n",
      "c) Sử dụng được các phương tiện, thiết bị kỹ thuật phục vụ yêu cầu nhiệm vụ;\n",
      "d) Có khả năng ứng dụng công nghệ thông tin cơ bản để thực hiện nhiệm vụ được giao.\n",
      "Điều 7. Nguyên tắc xếp lương chức danh nghề nghiệp đối với viên chức chuyên ngành tuyên truyền viên văn hóa\n",
      "1. Việc bổ nhiệm và xếp lương vào chức danh nghề nghiệp viên chức chuyên ngành tuyên truyền viên văn hóa quy định tại Thông tư này phải căn cứ vào vị trí việc làm, chức trách, nhiệm vụ và chuyên môn, nghiệp vụ đang đảm nhận của viên chức.\n",
      "2. Khi bổ nhiệm và xếp lương vào các chức danh nghề nghiệp viên chức chuyên ngành tuyên truyền viên văn hóa tương ứng không được kết hợp nâng bậc lương hoặc thăng hạng chức danh nghề nghiệp viên chức.\n",
      "Điều 8. Cách xếp lương\n",
      "1. Các chức danh nghề nghiệp viên chức chuyên ngành tuyên truyền viên văn hóa quy định tại Thông tư này được áp dụng Bảng 3 (Bảng lương chuyên môn, nghiệp vụ đối với cán bộ, viên chức trong các đơn vị sự nghiệp của Nhà nước) ban hành kèm theo Nghị định số 204/2004/NĐ-CP ngày 14 tháng 12 năm 2004 của Chính phủ về chế độ tiền lương đối với cán bộ, công chức, viên chức và lực lượng vũ trang (sau đây viết tắt là Nghị định số 204/2004/NĐ-CP), cụ thể như sau:\n",
      "a) Chức danh nghề nghiệp tuyên truyền viên văn hóa chính được áp dụng ngạch lương của viên chức loại A2, nhóm 2 (A2.2), từ hệ số lương 4,00 đến hệ số lương 6,38;\n",
      "b) Chức danh nghề nghiệp tuyên truyền viên văn hóa được áp dụng ngạch lương của viên chức loại A1, từ hệ số lương 2,34 đến hệ số lương 4,98;\n",
      "c) Chức danh nghề nghiệp tuyên truyền viên văn hóa trung cấp được áp dụng ngạch lương của viên chức loại B, từ hệ số lương 1,86 đến hệ số lương 4,06.\n",
      "2. Sau khi hết thời gian tập sự theo quy định và được cấp có thẩm quyền quản lý viên chức quyết định bổ nhiệm chức danh nghề nghiệp viên chức tuyên truyền viên văn hóa thì thực hiện xếp bậc lương theo chức danh nghề nghiệp được bổ nhiệm như sau:\n",
      "a) Trường hợp bổ nhiệm chức danh nghề nghiệp tuyên truyền viên văn hóa trung cấp:\n",
      "Viên chức có trình độ đào tạo trung cấp khi tuyển dụng, phù hợp với vị trí việc làm tuyển dụng được xếp bậc 1, hệ số lương 1,86, ngạch viên chức loại B;\n",
      "Viên chức có trình độ đào tạo cao đẳng trở lên khi tuyển dụng, phù hợp với vị trí việc làm tuyển dụng được xếp bậc 2, hệ số lương 2,06, ngạch viên chức loại B.\n",
      "b) Trường hợp bổ nhiệm chức danh nghề nghiệp tuyên truyền viên văn hóa:\n",
      "Viên chức có trình độ đào tạo đại học khi tuyển dụng, phù hợp với vị trí việc làm tuyển dụng được xếp bậc 1, hệ số lương 2,34, ngạch viên chức loại A1;\n",
      "Viên chức có trình độ đào tạo thạc sỹ khi tuyển dụng, phù hợp với vị trí việc làm tuyển dụng được xếp bậc 2, hệ số lương 2,67, ngạch viên chức loại A1;\n",
      "Viên chức có trình độ đào tạo tiến sỹ khi tuyển dụng, phù hợp với vị trí việc làm tuyển dụng được xếp bậc 3, hệ số lương 3,00, ngạch viên chức loại A1.\n",
      "3. Việc chuyển xếp lương đối với viên chức từ chức danh nghề nghiệp hiện giữ sang chức danh nghề nghiệp tuyên truyền viên văn hóa quy định tại Thông tư này thực hiện theo hướng dẫn tại Mục II Thông tư số 02/2007/TT- BNV ngày 25 tháng 5 năm 2007 của Bộ trưởng Bộ Nội vụ hướng dẫn xếp lương khi nâng ngạch, chuyển ngạch, chuyển loại công chức, viên chức (sau đây viết tắt là Thông tư số 02/2007/TT-BNV).\n",
      "Điều 9. Quy định chuyển tiếp\n",
      "1. Viên chức đã được bổ nhiệm vào các ngạch viên chức tuyên truyền viên theo quy định tại Quyết định số 428/TCCP-VC ngày 02 tháng 6 năm 1993 của Bộ trưởng - Trưởng ban Ban Tổ chức - Cán bộ Chính phủ (nay là Bộ trưởng Bộ Nội vụ) ban hành tiêu chuẩn nghiệp vụ ngạch công chức ngành Văn hóa - Thông tin (sau đây viết tắt là Quyết định số 428/TCCP-VC), Quyết định số 78/2004/QĐ-BNV ngày 03 tháng 11 năm 2004 của Bộ trưởng Bộ Nội vụ ban hành danh mục các ngạch công chức và ngạch viên chức (sau đây viết tắt là Quyết định số 78/2004/QĐ-BNV), Thông tư số 80/2005/TT-BNV ngày 10 tháng 8 năm 2005 của Bộ trưởng Bộ Nội vụ hướng dẫn thực hiện chuyển xếp lương đối với cán bộ, công chức, viên chức có trình độ cao đẳng phù hợp với chuyên môn đang làm được bổ nhiệm vào chức danh nghề nghiệp viên chức chuyên ngành tuyên truyền viên văn hóa quy định tại Thông tư này, như sau:\n",
      "a) Bổ nhiệm vào chức danh nghề nghiệp tuyên truyền viên văn hóa (mã số V.10.10.35) đối với viên chức hiện đang giữ ngạch tuyên truyền viên chính (mã số 17.177).\n",
      "b) Bổ nhiệm vào chức danh nghề nghiệp tuyên truyền viên văn hóa trung cấp (mã số V.10.10.36) đối với viên chức hiện đang giữ ngạch tuyên truyền viên cao đẳng (mã số 17a.177) hoặc tuyên truyền viên (mã số 17.178).\n",
      "2. Việc chuyển xếp lương vào chức danh nghề nghiệp viên chức quy định tại khoản 1 Điều này đối với viên chức đã được xếp lương vào các ngạch viên chức tuyên truyền viên theo quy định tại Quyết định số 428/TCCP-VC, Quyết định số 78/2004/QĐ-BNV và Nghị định số 204/2004/NĐ-CP được thực hiện theo hướng dẫn tại Thông tư số 02/2007/TT-BNV như sau:\n",
      "a) Trường hợp viên chức có hệ số bậc lương bằng ở ngạch cũ thì thực hiện xếp ngang bậc lương và % phụ cấp thâm niên vượt khung (nếu có) đang hưởng ở ngạch cũ (kể cả tính thời gian xét nâng bậc lương lần sau hoặc xét hưởng phụ cấp thâm niên vượt khung nếu có ở ngạch cũ) vào chức danh nghề nghiệp mới được bổ nhiệm.\n",
      "b) Trường hợp viên chức có trình độ cao đẳng khi tuyển dụng đã được xếp lương viên chức loại A0 theo quy định tại Nghị định số 204/2004/NĐ -CP nay được bổ nhiệm vào chức danh nghề nghiệp tuyên truyền viên văn hóa trung cấp thì việc xếp bậc lương căn cứ vào thời gian công tác có đóng bảo hiểm xã hội bắt buộc theo thang lương, bảng lương do Nhà nước quy định (trừ thời gian tập sự) như sau:\n",
      "Tính từ bậc 2 bảng lương viên chức loại B, cứ sau thời gian 02 năm (đủ 24 tháng) được xếp lên 01 bậc lương (nếu có thời gian đứt quãng mà chưa hưởng chế độ bảo hiểm xã hội thì được cộng dồn). Trường hợp trong thời gian công tác có năm không hoàn thành nhiệm vụ được giao hoặc bị kỷ luật thì bị kéo dài thêm theo chế độ nâng bậc lương thường xuyên. Trường hợp trong thời gian công tác được nâng bậc lương trước thời hạn do lập thành tích xuất sắc trong thực hiện nhiệm vụ thì thời gian được nâng bậc lương trước thời hạ n được tính để xếp lên bậc lương cao hơn trước thời hạn tương ứng. Sau khi quy đổi thời gian để xếp vào bậc lương của chức danh nghề nghiệp được bổ nhiệm, nếu có số tháng chưa đủ 24 tháng, thì số tháng này được tính vào thời gian để xét nâng bậc lương lần sau hoặc xét hưởng phụ cấp thâm niên vượt khung (nếu có).\n",
      "Sau khi chuyển xếp lương vào chức danh nghề nghiệp tuyên truyền viên văn hóa trung cấp nêu trên, nếu hệ số lương được xếp ở chức danh nghề nghiệp này cộng với phụ cấp thâm niên vượt khung (nếu có) thấp hơn hệ số lương đã hưởng ở ngạch cũ thì được hưởng hệ số chênh lệch bảo lưu cho bằng hệ số lương (kể cả phụ cấp thâm niên vượt khung, nếu có) đang hưởng ở ngạch cũ. Hệ số chênh lệch bảo lưu này được hưởng trong suốt thời gian viên chức xếp lương ở chức danh nghề nghiệp tuyên truyền viên văn hóa trung cấp. Sau đó, nếu viên chức được thăng hạng chức danh nghề nghiệp thì được cộng hệ số chênh lệch bảo lưu này vào hệ số lương (kể cả phụ cấp thâm niên vượt khung, nếu có) đang hưởng để xếp lương vào chức danh được bổ nhiệm khi thăng hạng chức danh nghề nghiệp và thôi hưởng hệ số chênh lệch bảo lưu kể từ ngày hưởng lương ở chức danh nghề nghiệp mới.\n",
      "3. Viên chức đã được bổ nhiệm vào các ngạch tuyên truyền viên theo quy định của pháp luật từ trước ngày Thông tư này có hiệu lực thi hành thì được xác định là đáp ứng quy định về tiêu chuẩn chức danh nghề nghiệp viên chức chuyên ngành tuyên truyền viên văn hóa quy định tại Thông tư này tương ứng với chức danh nghề nghiệp đã được bổ nhiệm.\n",
      "Điều 10. Tổ chức thực hiện\n",
      "1. Thông tư này là căn cứ để thực hiện việc tuyển dụng, sử dụng và quản lý viên chức chuyên ngành tuyên truyền viên văn hóa làm việc trong các đơn vị sự nghiệp công lập.\n",
      "2. Người đứng đầu các đơn vị sự nghiệp công lập trực tiếp quản lý và sử dụng viên chức có trách nhiệm:\n",
      "a) Rà soát vị trí việc làm của đơn vị, lập phương án bổ nhiệm chức danh nghề nghiệp viên chức chuyên ngành tuyên truyền viên văn hóa thuộc thẩm quyền quản lý, trình cấp có thẩm quyền xem xét, quyết định hoặc quyết định theo thẩm quyền phân cấp;\n",
      "b) Quyết định bổ nhiệm chức danh nghề nghiệp chuyên ngành tuyên truyền viên văn hóa trong các đơn vị sự nghiệp công lập theo thẩm quyền hoặc theo phân cấp, ủy quyền sau khi phương án bổ nhiệm chức danh nghề nghiệp được cấp có thẩm quyền phê duyệt.\n",
      "3. Các Bộ, cơ quan ngang Bộ, cơ quan thuộc Chính phủ, Ủy ban nhân dân tỉnh, thành phố trực thuộc trung ương có trách nhiệm:\n",
      "a) Chỉ đạo các đơn vị thuộc phạm vi quản lý thực hiện bổ nhiệm chức danh nghề nghiệp và xếp lương đối với viên chức giữ chức danh nghề nghiệp chuyên ngành tuyên truyền viên văn hóa theo quy định;\n",
      "b) Quyết định hoặc phân cấp, ủy quyền việc bổ nhiệm và xếp lương chức danh nghề nghiệp chuyên ngành tuyên truyền viên văn hóa đối với viên chức thuộc thẩm quyền quản lý; giải quyết theo thẩm quyền những vướng mắc trong quá trình bổ nhiệm chức danh nghề nghiệp và xếp lương.\n",
      "4. Các tổ chức, đơn vị sự nghiệp ngoài công lập có thể áp dụng quy định tại Thông tư này để tuyển dụng, sử dụng và quản lý đội ngũ người làm việc về chuyên ngành tuyên truyền viên văn hóa.\n",
      "Điều 11. Hiệu lực thi hành\n",
      "1. Thông tư này có hiệu lực thi hành kể từ ngày 10 tháng 4 năm 2023.\n",
      "2. Trường hợp các văn bản dẫn chiếu tại Thông tư này được sửa đổi, bổ sung hoặc thay thế thì thực hiện theo các văn bản đã được sửa đổi, bổ sung hoặc thay thế.\n",
      "Điều 12. Trách nhiệm thi hành\n",
      "1. Bộ trưởng, Thủ trưởng cơ quan ngang Bộ, Thủ trưởng cơ quan thuộc Chính phủ, Chủ tịch Ủy ban nhân dân tỉnh, thành phố trực thuộc trung ương và cơ quan, đơn vị, cá nhân có liên quan chịu trách nhiệm thi hành Thông tư này.\n",
      "2. Trong quá trình thực hiện nếu phát sinh vướng mắc, đề nghị cơ quan, đơn vị, cá nhân kịp thời phản ánh về Bộ Văn hóa, Thể thao và Du lịch để nghiên cứu sửa đổi, bổ sung cho phù hợp.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bình thường mặc định sẽ tìm kiếm bỏ qua \\n nhưng có re.DOTALL thì sẽ tìm cả \\n nên thích hợp tìm kiếm văn bản nhiều dòng \n",
    "test=re.findall(r\"Chương .+?(?=\\nChương .+|Nơi nhận)\",text,re.DOTALL)\n",
    "for i in test:\n",
    "    dieu=re.findall(r\"Điều \\d+\\..+(?=\\nĐiều \\d+\\.|$)\",i,re.DOTALL)\n",
    "    for j in dieu:\n",
    "        print(j)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 3.Tìm tất cả các mã luật có trong văn bản theo định dạng tương tự như: “204/2004/NĐ-CP”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02/2023/TT-BVHTTDL',\n",
       " '204/2004/NĐ-CP',\n",
       " '17/2013/NĐ-CP',\n",
       " '204/2004/NĐ-CP',\n",
       " '01/2023/NĐ-CP',\n",
       " '115/2020/NĐ-CP',\n",
       " '204/2004/NĐ-CP',\n",
       " '204/2004/NĐ-CP),',\n",
       " '02/2007/TT- BNV',\n",
       " '02/2007/TT-BNV).',\n",
       " '428/TCCP-VC',\n",
       " '428/TCCP-VC),',\n",
       " '78/2004/QĐ-BNV',\n",
       " '78/2004/QĐ-BNV),',\n",
       " '80/2005/TT-BNV',\n",
       " '428/TCCP-VC,',\n",
       " '78/2004/QĐ-BNV',\n",
       " '204/2004/NĐ-CP',\n",
       " '02/2007/TT-BNV',\n",
       " '204/2004/NĐ -CP']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_luat=re.findall(r\"\\d+/\\d{4}/.+?-.+?(?=\\s+)|\\d+/.+?-.+?(?=\\s+)\",text)\n",
    "ma_luat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping\n",
    "- Truy cập vào đường dẫn: https://arxiv.org/list/cs.AI/recent và sử dụng BeautifulSoup để thực\n",
    "hiện các yêu cầu sau đây:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 1. Lấy các đường dẫn đến các bài báo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_html(url):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        html = response.read()\n",
    "        html = html.decode('utf-8')\n",
    "    response.close()\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "url=\"https://arxiv.org/list/cs.AI/recent\"\n",
    "html=download_html(url)\n",
    "soup=BeautifulSoup(html,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://arxiv.org/abs/2305.16291',\n",
       " 'https://arxiv.org/abs/2305.16191',\n",
       " 'https://arxiv.org/abs/2305.16151',\n",
       " 'https://arxiv.org/abs/2305.15934',\n",
       " 'https://arxiv.org/abs/2305.15921',\n",
       " 'https://arxiv.org/abs/2305.15771',\n",
       " 'https://arxiv.org/abs/2305.15743',\n",
       " 'https://arxiv.org/abs/2305.15695',\n",
       " 'https://arxiv.org/abs/2305.15486',\n",
       " 'https://arxiv.org/abs/2305.16318',\n",
       " 'https://arxiv.org/abs/2305.16317',\n",
       " 'https://arxiv.org/abs/2305.16312',\n",
       " 'https://arxiv.org/abs/2305.16303',\n",
       " 'https://arxiv.org/abs/2305.16295',\n",
       " 'https://arxiv.org/abs/2305.16289',\n",
       " 'https://arxiv.org/abs/2305.16275',\n",
       " 'https://arxiv.org/abs/2305.16264',\n",
       " 'https://arxiv.org/abs/2305.16263',\n",
       " 'https://arxiv.org/abs/2305.16259',\n",
       " 'https://arxiv.org/abs/2305.16257',\n",
       " 'https://arxiv.org/abs/2305.16209',\n",
       " 'https://arxiv.org/abs/2305.16203',\n",
       " 'https://arxiv.org/abs/2305.16196',\n",
       " 'https://arxiv.org/abs/2305.16195',\n",
       " 'https://arxiv.org/abs/2305.16192']"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_blocks = soup.find_all('span',  {'class':'list-identifier'})\n",
    "links=[]\n",
    "for i in doc_blocks:\n",
    "    text=str(i.find('a',{'title':'Abstract'}).get('href'))\n",
    "    links.append(\"https://arxiv.org\"+text)\n",
    "links"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 2. Đi đến đường dẫn mỗi bài báo, trích xuất các thông tin như: tên bài báo, tên tác giả, abstract của bài báo, subjects, đường dẫn download bài báo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_doc_data(link):\n",
    "    author=[]\n",
    "    html=download_html(link)\n",
    "    soup=BeautifulSoup(html,\"lxml\")\n",
    "    doc_name=soup.find('h1',{'class':'title mathjax'}).contents[1]\n",
    "    for j in soup.find('div',{'class':'authors'}).find_all('a'):\n",
    "        author.append(j.text)\n",
    "    abstract=soup.find('blockquote',{'class':'abstract mathjax'}).text[1:] #[1:] vì để bỏ dấu \\n ở đầu chuỗi\n",
    "    subject=soup.find('td',{'class':'tablecell subjects'}).text[1:]\n",
    "    download=str(\"https://arxiv.org\"+soup.find('a',{'class':'abs-button download-pdf'}).get('href'))\n",
    "    return doc_name,author,abstract,subject,download\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bài báo số 1:\n",
      "Tên bài báo:\n",
      "Voyager: An Open-Ended Embodied Agent with Large Language Models\n",
      "Tên tác giả:\n",
      "['Guanzhi Wang', 'Yuqi Xie', 'Yunfan Jiang', 'Ajay Mandlekar', 'Chaowei Xiao', 'Yuke Zhu', 'Linxi Fan', 'Anima Anandkumar']\n",
      "Tóm tắt:\n",
      "Abstract:  We introduce Voyager, the first LLM-powered embodied lifelong learning agent\n",
      "in Minecraft that continuously explores the world, acquires diverse skills, and\n",
      "makes novel discoveries without human intervention. Voyager consists of three\n",
      "key components: 1) an automatic curriculum that maximizes exploration, 2) an\n",
      "ever-growing skill library of executable code for storing and retrieving\n",
      "complex behaviors, and 3) a new iterative prompting mechanism that incorporates\n",
      "environment feedback, execution errors, and self-verification for program\n",
      "improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses\n",
      "the need for model parameter fine-tuning. The skills developed by Voyager are\n",
      "temporally extended, interpretable, and compositional, which compounds the\n",
      "agent's abilities rapidly and alleviates catastrophic forgetting. Empirically,\n",
      "Voyager shows strong in-context lifelong learning capability and exhibits\n",
      "exceptional proficiency in playing Minecraft. It obtains 3.3x more unique\n",
      "items, travels 2.3x longer distances, and unlocks key tech tree milestones up\n",
      "to 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill\n",
      "library in a new Minecraft world to solve novel tasks from scratch, while other\n",
      "techniques struggle to generalize. We open-source our full codebase and prompts\n",
      "at this https URL.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16291\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 2:\n",
      "Tên bài báo:\n",
      "UpMax: User partitioning for MaxSAT\n",
      "Tên tác giả:\n",
      "['Pedro Orvalho', 'Vasco Manquinho', 'Ruben Martins']\n",
      "Tóm tắt:\n",
      "Abstract:  It has been shown that Maximum Satisfiability (MaxSAT) problem instances can\n",
      "be effectively solved by partitioning the set of soft clauses into several\n",
      "disjoint sets. The partitioning methods can be based on clause weights (e.g.,\n",
      "stratification) or based on graph representations of the formula. Afterwards, a\n",
      "merge procedure is applied to guarantee that an optimal solution is found.\n",
      "This paper proposes a new framework called UpMax that decouples the\n",
      "partitioning procedure from the MaxSAT solving algorithms. As a result, new\n",
      "partitioning procedures can be defined independently of the MaxSAT algorithm to\n",
      "be used. Moreover, this decoupling also allows users that build new MaxSAT\n",
      "formulas to propose partition schemes based on knowledge of the problem to be\n",
      "solved. We illustrate this approach using several problems and show that\n",
      "partitioning has a large impact on the performance of unsatisfiability-based\n",
      "MaxSAT algorithms.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16191\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 3:\n",
      "Tên bài báo:\n",
      "Understanding the Capabilities of Large Language Models for Automated Planning\n",
      "Tên tác giả:\n",
      "['Vishal Pallagani', 'Bharath Muppasani', 'Keerthiram Murugesan', 'Francesca Rossi', 'Biplav Srivastava', 'Lior Horesh', 'Francesco Fabiano', 'Andrea Loreggia']\n",
      "Tóm tắt:\n",
      "Abstract:  Automated planning is concerned with developing efficient algorithms to\n",
      "generate plans or sequences of actions to achieve a specific goal in a given\n",
      "environment. Emerging Large Language Models (LLMs) can answer questions, write\n",
      "high-quality programming code, and predict protein folding, showcasing their\n",
      "versatility in solving various tasks beyond language-based problems. In this\n",
      "paper, we aim to explore how LLMs can also be used for automated planning. To\n",
      "do so, we seek to answer four key questions. Firstly, we want to understand the\n",
      "extent to which LLMs can be used for plan generation. Secondly, we aim to\n",
      "identify which pre-training data is most effective in facilitating plan\n",
      "generation. Thirdly, we investigate whether fine-tuning or prompting is a more\n",
      "effective approach for plan generation. Finally, we explore whether LLMs are\n",
      "capable of plan generalization. By answering these questions, the study seeks\n",
      "to shed light on the capabilities of LLMs in solving complex planning problems\n",
      "and provide insights into the most effective approaches for using LLMs in this\n",
      "context.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16151\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 4:\n",
      "Tên bài báo:\n",
      "A Diagnosis Algorithms for a Rotary Indexing Machine\n",
      "Tên tác giả:\n",
      "['Maria Krantz', 'Oliver Niggemann']\n",
      "Tóm tắt:\n",
      "Abstract:  Rotary Indexing Machines (RIMs) are widely used in manufacturing due to their\n",
      "ability to perform multiple production steps on a single product without manual\n",
      "repositioning, reducing production time and improving accuracy and consistency.\n",
      "Despite their advantages, little research has been done on diagnosing faults in\n",
      "RIMs, especially from the perspective of the actual production steps carried\n",
      "out on these machines. Long downtimes due to failures are problematic,\n",
      "especially for smaller companies employing these machines. To address this gap,\n",
      "we propose a diagnosis algorithm based on the product perspective, which\n",
      "focuses on the product being processed by RIMs. The algorithm traces the steps\n",
      "that a product takes through the machine and is able to diagnose possible\n",
      "causes in case of failure. We also analyze the properties of RIMs and how these\n",
      "influence the diagnosis of faults in these machines. Our contributions are\n",
      "three-fold. Firstly, we provide an analysis of the properties of RIMs and how\n",
      "they influence the diagnosis of faults in these machines. Secondly, we suggest\n",
      "a diagnosis algorithm based on the product perspective capable of diagnosing\n",
      "faults in such a machine. Finally, we test this algorithm on a model of a\n",
      "rotary indexing machine, demonstrating its effectiveness in identifying faults\n",
      "and their root causes.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.15934\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 5:\n",
      "Tên bài báo:\n",
      "Learning Assumption-based Argumentation Frameworks\n",
      "Tên tác giả:\n",
      "['Maurizio Proietti', 'Francesca Toni']\n",
      "Tóm tắt:\n",
      "Abstract:  We propose a novel approach to logic-based learning which generates\n",
      "assumption-based argumentation (ABA) frameworks from positive and negative\n",
      "examples, using a given background knowledge. These ABA frameworks can be\n",
      "mapped onto logic programs with negation as failure that may be non-stratified.\n",
      "Whereas existing argumentation-based methods learn exceptions to general rules\n",
      "by interpreting the exceptions as rebuttal attacks, our approach interprets\n",
      "them as undercutting attacks. Our learning technique is based on the use of\n",
      "transformation rules, including some adapted from logic program transformation\n",
      "rules (notably folding) as well as others, such as rote learning and assumption\n",
      "introduction. We present a general strategy that applies the transformation\n",
      "rules in a suitable order to learn stratified frameworks, and we also propose a\n",
      "variant that handles the non-stratified case. We illustrate the benefits of our\n",
      "approach with a number of examples, which show that, on one hand, we are able\n",
      "to easily reconstruct other logic-based learning approaches and, on the other\n",
      "hand, we can work out in a very simple and natural way problems that seem to be\n",
      "hard for existing techniques.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.15921\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 6:\n",
      "Tên bài báo:\n",
      "On the Planning Abilities of Large Language Models -- A Critical Investigation\n",
      "Tên tác giả:\n",
      "['Karthik Valmeekam', 'Matthew Marquez', 'Sarath Sreedharan', 'Subbarao Kambhampati']\n",
      "Tóm tắt:\n",
      "Abstract:  Intrigued by the claims of emergent reasoning capabilities in LLMs trained on\n",
      "general web corpora, in this paper, we set out to investigate their planning\n",
      "capabilities. We aim to evaluate (1) the effectiveness of LLMs in generating\n",
      "plans autonomously in commonsense planning tasks and (2) the potential of LLMs\n",
      "as a source of heuristic guidance for other agents (AI planners) in their\n",
      "planning tasks. We conduct a systematic study by generating a suite of\n",
      "instances on domains similar to the ones employed in the International Planning\n",
      "Competition and evaluate LLMs in two distinct modes: autonomous and heuristic.\n",
      "Our findings reveal that LLMs' ability to generate executable plans\n",
      "autonomously is rather limited, with the best model (GPT-4) having an average\n",
      "success rate of ~12% across the domains. However, the results in the heuristic\n",
      "mode show more promise. In the heuristic mode, we demonstrate that\n",
      "LLM-generated plans can improve the search process for underlying sound\n",
      "planners and additionally show that external verifiers can help provide\n",
      "feedback on the generated plans and back-prompt the LLM for better plan\n",
      "generation.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.15771\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 7:\n",
      "Tên bài báo:\n",
      "TransWorldNG: Traffic Simulation via Foundation Model\n",
      "Tên tác giả:\n",
      "['Ding Wang', 'Xuhong Wang', 'Liang Chen', 'Shengyue Yao', 'Ming Jing', 'Honghai Li', 'Li Li', 'Shiqiang Bao', 'Fei-Yue Wang', 'Yilun Lin']\n",
      "Tóm tắt:\n",
      "Abstract:  Traffic simulation is a crucial tool for transportation decision-making and\n",
      "policy development. However, achieving realistic simulations in the face of the\n",
      "high dimensionality and heterogeneity of traffic environments is a longstanding\n",
      "challenge. In this paper, we present TransWordNG, a traffic simulator that uses\n",
      "Data-driven algorithms and Graph Computing techniques to learn traffic dynamics\n",
      "from real data. The functionality and structure of TransWorldNG are introduced,\n",
      "which utilize a foundation model for transportation management and control. The\n",
      "results demonstrate that TransWorldNG can generate more realistic traffic\n",
      "patterns compared to traditional simulators. Additionally, TransWorldNG\n",
      "exhibits better scalability, as it shows linear growth in computation time as\n",
      "the scenario scale increases. To the best of our knowledge, this is the first\n",
      "traffic simulator that can automatically learn traffic patterns from real-world\n",
      "data and efficiently generate accurate and realistic traffic environments.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.15743\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 8:\n",
      "Tên bài báo:\n",
      "Asking Before Action: Gather Information in Embodied Decision Making with Language Models\n",
      "Tên tác giả:\n",
      "['Xiaoyu Chen', 'Shenao Zhang', 'Pushi Zhang', 'Li Zhao', 'Jianyu Chen']\n",
      "Tóm tắt:\n",
      "Abstract:  With strong capabilities of reasoning and a generic understanding of the\n",
      "world, Large Language Models (LLMs) have shown great potential in building\n",
      "versatile embodied decision making agents capable of performing diverse tasks.\n",
      "However, when deployed to unfamiliar environments, we show that LLM agents face\n",
      "challenges in efficiently gathering necessary information, leading to\n",
      "suboptimal performance. On the other hand, in unfamiliar scenarios, human\n",
      "individuals often seek additional information from their peers before taking\n",
      "action, leveraging external knowledge to avoid unnecessary trial and error.\n",
      "Building upon this intuition, we propose \\textit{Asking Before Action} (ABA), a\n",
      "method that empowers the agent to proactively query external sources for\n",
      "pertinent information using natural language during their interactions in the\n",
      "environment. In this way, the agent is able to enhance its efficiency and\n",
      "performance by mitigating wasteful steps and circumventing the difficulties\n",
      "associated with exploration in unfamiliar environments. We empirically evaluate\n",
      "our method on an embodied decision making benchmark, ALFWorld, and demonstrate\n",
      "that despite modest modifications in prompts, our method exceeds baseline LLM\n",
      "agents by more than $40$%. Further experiments on two variants of ALFWorld\n",
      "illustrate that by imitation learning, ABA effectively retains and reuses\n",
      "queried and known information in subsequent tasks, mitigating the need for\n",
      "repetitive inquiries. Both qualitative and quantitative results exhibit\n",
      "remarkable performance on tasks that previous methods struggle to solve.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.15695\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 9:\n",
      "Tên bài báo:\n",
      "SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning\n",
      "Tên tác giả:\n",
      "['Yue Wu', 'So Yeon Min', 'Shrimai Prabhumoye', 'Yonatan Bisk', 'Ruslan Salakhutdinov', 'Amos Azaria', 'Tom Mitchell', 'Yuanzhi Li']\n",
      "Tóm tắt:\n",
      "Abstract:  Open-world survival games pose significant challenges for AI algorithms due\n",
      "to their multi-tasking, deep exploration, and goal prioritization requirements.\n",
      "Despite reinforcement learning (RL) being popular for solving games, its high\n",
      "sample complexity limits its effectiveness in complex open-world games like\n",
      "Crafter or Minecraft. We propose a novel approach, SPRING, to read the game's\n",
      "original academic paper and use the knowledge learned to reason and play the\n",
      "game through a large language model (LLM). Prompted with the LaTeX source as\n",
      "game context and a description of the agent's current observation, our SPRING\n",
      "framework employs a directed acyclic graph (DAG) with game-related questions as\n",
      "nodes and dependencies as edges. We identify the optimal action to take in the\n",
      "environment by traversing the DAG and calculating LLM responses for each node\n",
      "in topological order, with the LLM's answer to final node directly translating\n",
      "to environment actions. In our experiments, we study the quality of in-context\n",
      "\"reasoning\" induced by different forms of prompts under the setting of the\n",
      "Crafter open-world environment. Our experiments suggest that LLMs, when\n",
      "prompted with consistent chain-of-thought, have great potential in completing\n",
      "sophisticated high-level trajectories. Quantitatively, SPRING with GPT-4\n",
      "outperforms all state-of-the-art RL baselines, trained for 1M steps, without\n",
      "any training. Finally, we show the potential of games as a test bed for LLMs.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.15486\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 10:\n",
      "Tên bài báo:\n",
      "Referred by Multi-Modality: A Unified Temporal Transformer for Video Object Segmentation\n",
      "Tên tác giả:\n",
      "['Shilin Yan', 'Renrui Zhang', 'Ziyu Guo', 'Wenchao Chen', 'Wei Zhang', 'Hongyang Li', 'Yu Qiao', 'Zhongjiang He', 'Peng Gao']\n",
      "Tóm tắt:\n",
      "Abstract:  Recently, video object segmentation (VOS) referred by multi-modal signals,\n",
      "e.g., language and audio, has evoked increasing attention in both industry and\n",
      "academia. It is challenging for exploring the semantic alignment within\n",
      "modalities and the visual correspondence across frames. However, existing\n",
      "methods adopt separate network architectures for different modalities, and\n",
      "neglect the inter-frame temporal interaction with references. In this paper, we\n",
      "propose MUTR, a Multi-modal Unified Temporal transformer for Referring video\n",
      "object segmentation. With a unified framework for the first time, MUTR adopts a\n",
      "DETR-style transformer and is capable of segmenting video objects designated by\n",
      "either text or audio reference. Specifically, we introduce two strategies to\n",
      "fully explore the temporal relations between videos and multi-modal signals.\n",
      "Firstly, for low-level temporal aggregation before the transformer, we enable\n",
      "the multi-modal references to capture multi-scale visual cues from consecutive\n",
      "video frames. This effectively endows the text or audio signals with temporal\n",
      "knowledge and boosts the semantic alignment between modalities. Secondly, for\n",
      "high-level temporal interaction after the transformer, we conduct inter-frame\n",
      "feature communication for different object embeddings, contributing to better\n",
      "object-wise correspondence for tracking along the video. On Ref-YouTube-VOS and\n",
      "AVSBench datasets with respective text and audio references, MUTR achieves\n",
      "+4.2% and +4.2% J&F improvements to state-of-the-art methods, demonstrating our\n",
      "significance for unified multi-modal VOS. Code is released at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multimedia (cs.MM)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16318\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 11:\n",
      "Tên bài báo:\n",
      "Parallel Sampling of Diffusion Models\n",
      "Tên tác giả:\n",
      "['Andy Shih', 'Suneel Belkhale', 'Stefano Ermon', 'Dorsa Sadigh', 'Nima Anari']\n",
      "Tóm tắt:\n",
      "Abstract:  Diffusion models are powerful generative models but suffer from slow\n",
      "sampling, often taking 1000 sequential denoising steps for one sample. As a\n",
      "result, considerable efforts have been directed toward reducing the number of\n",
      "denoising steps, but these methods hurt sample quality. Instead of reducing the\n",
      "number of denoising steps (trading quality for speed), in this paper we explore\n",
      "an orthogonal approach: can we run the denoising steps in parallel (trading\n",
      "compute for speed)? In spite of the sequential nature of the denoising steps,\n",
      "we show that surprisingly it is possible to parallelize sampling via Picard\n",
      "iterations, by guessing the solution of future denoising steps and iteratively\n",
      "refining until convergence. With this insight, we present ParaDiGMS, a novel\n",
      "method to accelerate the sampling of pretrained diffusion models by denoising\n",
      "multiple steps in parallel. ParaDiGMS is the first diffusion sampling method\n",
      "that enables trading compute for speed and is even compatible with existing\n",
      "fast sampling techniques such as DDIM and DPMSolver. Using ParaDiGMS, we\n",
      "improve sampling speed by 2-4x across a range of robotics and image generation\n",
      "models, giving state-of-the-art sampling speeds of 0.2s on 100-step\n",
      "DiffusionPolicy and 16s on 1000-step StableDiffusion-v2 with no measurable\n",
      "degradation of task reward, FID score, or CLIP score.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16317\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 12:\n",
      "Tên bài báo:\n",
      "UMat: Uncertainty-Aware Single Image High Resolution Material Capture\n",
      "Tên tác giả:\n",
      "['Carlos Rodriguez-Pardo', 'Henar Dominguez-Elvira', 'David Pascual-Hernandez', 'Elena Garces']\n",
      "Tóm tắt:\n",
      "Abstract:  We propose a learning-based method to recover normals, specularity, and\n",
      "roughness from a single diffuse image of a material, using microgeometry\n",
      "appearance as our primary cue. Previous methods that work on single images tend\n",
      "to produce over-smooth outputs with artifacts, operate at limited resolution,\n",
      "or train one model per class with little room for generalization. Previous\n",
      "methods that work on single images tend to produce over-smooth outputs with\n",
      "artifacts, operate at limited resolution, or train one model per class with\n",
      "little room for generalization. In contrast, in this work, we propose a novel\n",
      "capture approach that leverages a generative network with attention and a U-Net\n",
      "discriminator, which shows outstanding performance integrating global\n",
      "information at reduced computational complexity. We showcase the performance of\n",
      "our method with a real dataset of digitized textile materials and show that a\n",
      "commodity flatbed scanner can produce the type of diffuse illumination required\n",
      "as input to our method. Additionally, because the problem might be illposed\n",
      "-more than a single diffuse image might be needed to disambiguate the specular\n",
      "reflection- or because the training dataset is not representative enough of the\n",
      "real distribution, we propose a novel framework to quantify the model's\n",
      "confidence about its prediction at test time. Our method is the first one to\n",
      "deal with the problem of modeling uncertainty in material digitization,\n",
      "increasing the trustworthiness of the process and enabling more intelligent\n",
      "strategies for dataset creation, as we demonstrate with an active learning\n",
      "experiment.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16312\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 13:\n",
      "Tên bài báo:\n",
      "Fine-Grained Complexity Analysis of Multi-Agent Path Finding on 2D Grids\n",
      "Tên tác giả:\n",
      "['Tzvika Geft']\n",
      "Tóm tắt:\n",
      "Abstract:  Multi-Agent Path Finding (MAPF) is a fundamental motion coordination problem\n",
      "arising in multi-agent systems with a wide range of applications. The problem's\n",
      "intractability has led to extensive research on improving the scalability of\n",
      "solvers for it. Since optimal solvers can struggle to scale, a major challenge\n",
      "that arises is understanding what makes MAPF hard. We tackle this challenge\n",
      "through a fine-grained complexity analysis of time-optimal MAPF on 2D grids,\n",
      "thereby closing two gaps and identifying a new tractability frontier. First, we\n",
      "show that 2-colored MAPF, i.e., where the agents are divided into two teams,\n",
      "each with its own set of targets, remains NP-hard. Second, for the flowtime\n",
      "objective (also called sum-of-costs), we show that it remains NP-hard to find a\n",
      "solution in which agents have an individually optimal cost, which we call an\n",
      "individually optimal solution. The previously tightest results for these MAPF\n",
      "variants are for (non-grid) planar graphs. We use a single hardness\n",
      "construction that replaces, strengthens, and unifies previous proofs. We\n",
      "believe that it is also simpler than previous proofs for the planar case as it\n",
      "employs minimal gadgets that enable its full visualization in one figure.\n",
      "Finally, for the flowtime objective, we establish a tractability frontier based\n",
      "on the number of directions agents can move in. Namely, we complement our\n",
      "hardness result, which holds for three directions, with an efficient algorithm\n",
      "for finding an individually optimal solution if only two directions are\n",
      "allowed. This result sheds new light on the structure of optimal solutions,\n",
      "which may help guide algorithm design for the general problem.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computational Geometry (cs.CG); Robotics (cs.RO)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16303\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 14:\n",
      "Tên bài báo:\n",
      "HAAV: Hierarchical Aggregation of Augmented Views for Image Captioning\n",
      "Tên tác giả:\n",
      "['Chia-Wen Kuo', 'Zsolt Kira']\n",
      "Tóm tắt:\n",
      "Abstract:  A great deal of progress has been made in image captioning, driven by\n",
      "research into how to encode the image using pre-trained models. This includes\n",
      "visual encodings (e.g. image grid features or detected objects) and more\n",
      "recently textual encodings (e.g. image tags or text descriptions of image\n",
      "regions). As more advanced encodings are available and incorporated, it is\n",
      "natural to ask: how to efficiently and effectively leverage the heterogeneous\n",
      "set of encodings? In this paper, we propose to regard the encodings as\n",
      "augmented views of the input image. The image captioning model encodes each\n",
      "view independently with a shared encoder efficiently, and a contrastive loss is\n",
      "incorporated across the encoded views in a novel way to improve their\n",
      "representation quality and the model's data efficiency. Our proposed\n",
      "hierarchical decoder then adaptively weighs the encoded views according to\n",
      "their effectiveness for caption generation by first aggregating within each\n",
      "view at the token level, and then across views at the view level. We\n",
      "demonstrate significant performance improvements of +5.6% CIDEr on MS-COCO and\n",
      "+12.9% CIDEr on Flickr30k compared to state of the arts, and conduct rigorous\n",
      "analyses to demonstrate the importance of each part of our design.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16295\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 15:\n",
      "Tên bài báo:\n",
      "Diversify Your Vision Datasets with Automatic Diffusion-Based Augmentation\n",
      "Tên tác giả:\n",
      "['Lisa Dunlap', 'Alyssa Umino', 'Han Zhang', 'Jiezhi Yang', 'Joseph E. Gonzalez', 'Trevor Darrell']\n",
      "Tóm tắt:\n",
      "Abstract:  Many fine-grained classification tasks, like rare animal identification, have\n",
      "limited training data and consequently classifiers trained on these datasets\n",
      "often fail to generalize to variations in the domain like changes in weather or\n",
      "location. As such, we explore how natural language descriptions of the domains\n",
      "seen in training data can be used with large vision models trained on diverse\n",
      "pretraining datasets to generate useful variations of the training data. We\n",
      "introduce ALIA (Automated Language-guided Image Augmentation), a method which\n",
      "utilizes large vision and language models to automatically generate natural\n",
      "language descriptions of a dataset's domains and augment the training data via\n",
      "language-guided image editing. To maintain data integrity, a model trained on\n",
      "the original dataset filters out minimal image edits and those which corrupt\n",
      "class-relevant information. The resulting dataset is visually consistent with\n",
      "the original training data and offers significantly enhanced diversity. On\n",
      "fine-grained and cluttered datasets for classification and detection, ALIA\n",
      "surpasses traditional data augmentation and text-to-image generated data by up\n",
      "to 15\\%, often even outperforming equivalent additions of real data. Code is\n",
      "avilable at this https URL.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16289\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 16:\n",
      "Tên bài báo:\n",
      "CENSUS-HWR: a large training dataset for offline handwriting recognition\n",
      "Tên tác giả:\n",
      "['Chetan Joshi', 'Lawry Sorenson', 'Ammon Wolfert', 'Dr. Mark Clement', 'Dr. Joseph Price', 'Dr. Kasey Buckles']\n",
      "Tóm tắt:\n",
      "Abstract:  Progress in Automated Handwriting Recognition has been hampered by the lack\n",
      "of large training datasets. Nearly all research uses a set of small datasets\n",
      "that often cause models to overfit. We present CENSUS-HWR, a new dataset\n",
      "consisting of full English handwritten words in 1,812,014 gray scale images. A\n",
      "total of 1,865,134 handwritten texts from a vocabulary of 10,711 words in the\n",
      "English language are present in this collection. This dataset is intended to\n",
      "serve handwriting models as a benchmark for deep learning algorithms. This huge\n",
      "English handwriting recognition dataset has been extracted from the US 1930 and\n",
      "1940 censuses taken by approximately 70,000 enumerators each year. The dataset\n",
      "and the trained model with their weights are freely available to download at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16275\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 17:\n",
      "Tên bài báo:\n",
      "Scaling Data-Constrained Language Models\n",
      "Tên tác giả:\n",
      "['Niklas Muennighoff', 'Alexander M. Rush', 'Boaz Barak', 'Teven Le Scao', 'Aleksandra Piktus', 'Nouamane Tazi', 'Sampo Pyysalo', 'Thomas Wolf', 'Colin Raffel']\n",
      "Tóm tắt:\n",
      "Abstract:  The current trend of scaling language models involves increasing both\n",
      "parameter count and training dataset size. Extrapolating this trend suggests\n",
      "that training dataset size may soon be limited by the amount of text data\n",
      "available on the internet. Motivated by this limit, we investigate scaling\n",
      "language models in data-constrained regimes. Specifically, we run a large set\n",
      "of experiments varying the extent of data repetition and compute budget,\n",
      "ranging up to 900 billion training tokens and 9 billion parameter models. We\n",
      "find that with constrained data for a fixed compute budget, training with up to\n",
      "4 epochs of repeated data yields negligible changes to loss compared to having\n",
      "unique data. However, with more repetition, the value of adding compute\n",
      "eventually decays to zero. We propose and empirically validate a scaling law\n",
      "for compute optimality that accounts for the decreasing value of repeated\n",
      "tokens and excess parameters. Finally, we experiment with approaches mitigating\n",
      "data scarcity, including augmenting the training dataset with code data or\n",
      "removing commonly used filters. Models and datasets from our 400 training runs\n",
      "are publicly available at this https URL.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16264\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 18:\n",
      "Tên bài báo:\n",
      "Unified Modeling of Multi-Talker Overlapped Speech Recognition and Diarization with a Sidecar Separator\n",
      "Tên tác giả:\n",
      "['Lingwei Meng', 'Jiawen Kang', 'Mingyu Cui', 'Haibin Wu', 'Xixin Wu', 'Helen Meng']\n",
      "Tóm tắt:\n",
      "Abstract:  Multi-talker overlapped speech poses a significant challenge for speech\n",
      "recognition and diarization. Recent research indicated that these two tasks are\n",
      "inter-dependent and complementary, motivating us to explore a unified modeling\n",
      "method to address them in the context of overlapped speech. A recent study\n",
      "proposed a cost-effective method to convert a single-talker automatic speech\n",
      "recognition (ASR) system into a multi-talker one, by inserting a Sidecar\n",
      "separator into the frozen well-trained ASR model. Extending on this, we\n",
      "incorporate a diarization branch into the Sidecar, allowing for unified\n",
      "modeling of both ASR and diarization with a negligible overhead of only 768\n",
      "parameters. The proposed method yields better ASR results compared to the\n",
      "baseline on LibriMix and LibriSpeechMix datasets. Moreover, without\n",
      "sophisticated customization on the diarization task, our method achieves\n",
      "acceptable diarization results on the two-speaker subset of CALLHOME with only\n",
      "a few adaptation steps.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Sound (cs.SD); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16263\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 19:\n",
      "Tên bài báo:\n",
      "Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art\n",
      "Tên tác giả:\n",
      "['Dimitrios Tsirmpas', 'Ioannis Gkionis', 'Ioannis Mademlis']\n",
      "Tóm tắt:\n",
      "Abstract:  The adoption of Deep Neural Networks (DNNs) has greatly benefited Natural\n",
      "Language Processing (NLP) during the past decade. However, the demands of long\n",
      "documents analysis are quite different from those of shorter texts, with the\n",
      "ever increasing size of documents uploaded online rendering NLP on long\n",
      "documents a critical area of research. This paper surveys the current\n",
      "state-of-the-art in the domain, overviewing the relevant neural building blocks\n",
      "and subsequently focusing on two main NLP tasks: Document Classification,\n",
      "Summarization as well as mentioning uses in Sentiment Analysis. We detail the\n",
      "challenges, issues and current solutions related to long-document NLP. We also\n",
      "list publicly available, labelled, long-document datasets used in current\n",
      "research.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16259\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 20:\n",
      "Tên bài báo:\n",
      "Fast Online Node Labeling for Very Large Graphs\n",
      "Tên tác giả:\n",
      "['Baojian Zhou', 'Yifan Sun', 'Reza Babanezhad']\n",
      "Tóm tắt:\n",
      "Abstract:  This paper studies the online node classification problem under a\n",
      "transductive learning setting. Current methods either invert a graph kernel\n",
      "matrix with $\\mathcal{O}(n^3)$ runtime and $\\mathcal{O}(n^2)$ space complexity\n",
      "or sample a large volume of random spanning trees, thus are difficult to scale\n",
      "to large graphs. In this work, we propose an improvement based on the\n",
      "\\textit{online relaxation} technique introduced by a series of works (Rakhlin\n",
      "et al.,2012; Rakhlin and Sridharan, 2015; 2017). We first prove an effective\n",
      "regret $\\mathcal{O}(\\sqrt{n^{1+\\gamma}})$ when suitable parameterized graph\n",
      "kernels are chosen, then propose an approximate algorithm FastONL enjoying\n",
      "$\\mathcal{O}(k\\sqrt{n^{1+\\gamma}})$ regret based on this relaxation. The key of\n",
      "FastONL is a \\textit{generalized local push} method that effectively\n",
      "approximates inverse matrix columns and applies to a series of popular kernels.\n",
      "Furthermore, the per-prediction cost is\n",
      "$\\mathcal{O}(\\text{vol}({\\mathcal{S}})\\log 1/\\epsilon)$ locally dependent on\n",
      "the graph with linear memory cost. Experiments show that our scalable method\n",
      "enjoys a better tradeoff between local and global consistency.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Spectral Theory (math.SP)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16257\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 21:\n",
      "Tên bài báo:\n",
      "C-MCTS: Safe Planning with Monte Carlo Tree Search\n",
      "Tên tác giả:\n",
      "['Dinesh Parthasarathy', 'Georgios Kontes', 'Axel Plinge', 'Christopher Mutschler']\n",
      "Tóm tắt:\n",
      "Abstract:  Many real-world decision-making tasks, such as safety-critical scenarios,\n",
      "cannot be fully described in a single-objective setting using the Markov\n",
      "Decision Process (MDP) framework, as they include hard constraints. These can\n",
      "instead be modeled with additional cost functions within the Constrained Markov\n",
      "Decision Process (CMDP) framework. Even though CMDPs have been extensively\n",
      "studied in the Reinforcement Learning literature, little attention has been\n",
      "given to sampling-based planning algorithms such as MCTS for solving them.\n",
      "Previous approaches use Monte Carlo cost estimates to avoid constraint\n",
      "violations. However, these suffer from high variance which results in\n",
      "conservative performance with respect to costs. We propose Constrained MCTS\n",
      "(C-MCTS), an algorithm that estimates cost using a safety critic. The safety\n",
      "critic training is based on Temporal Difference learning in an offline phase\n",
      "prior to agent deployment. This critic limits the exploration of the search\n",
      "tree and removes unsafe trajectories within MCTS during deployment. C-MCTS\n",
      "satisfies cost constraints but operates closer to the constraint boundary,\n",
      "achieving higher rewards compared to previous work. As a nice byproduct, the\n",
      "planner is more efficient requiring fewer planning steps. Most importantly, we\n",
      "show that under model mismatch between the planner and the real world, our\n",
      "approach is less susceptible to cost violations than previous work.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16209\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 22:\n",
      "Tên bài báo:\n",
      "On Computing Universal Plans for Partially Observable Multi-Agent Path Finding\n",
      "Tên tác giả:\n",
      "['Fengming Zhu', 'Fangzhen Lin']\n",
      "Tóm tắt:\n",
      "Abstract:  Multi-agent routing problems have drawn significant attention nowadays due to\n",
      "their broad industrial applications in, e.g., warehouse robots, logistics\n",
      "automation, and traffic control. Conventionally, they are modelled as classical\n",
      "planning problems. In this paper, we argue that it is beneficial to formulate\n",
      "them as universal planning problems. We therefore propose universal plans, also\n",
      "known as policies, as the solution concepts, and implement a system called\n",
      "ASP-MAUPF (Answer Set Programming for Multi-Agent Universal Plan Finding) for\n",
      "computing them. Given an arbitrary two-dimensional map and a profile of goals\n",
      "for the agents, the system finds a feasible universal plan for each agent that\n",
      "ensures no collision with others. We use the system to conduct some\n",
      "experiments, and make some observations on the types of goal profiles and\n",
      "environments that will have feasible policies, and how they may depend on\n",
      "agents' sensors. We also demonstrate how users can customize action preferences\n",
      "to compute more efficient policies, even (near-)optimal ones.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16203\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 23:\n",
      "Tên bài báo:\n",
      "Optimization and Interpretability of Graph Attention Networks for Small Sparse Graph Structures in Automotive Applications\n",
      "Tên tác giả:\n",
      "['Marion Neumeier', 'Andreas Tollkühn', 'Sebastian Dorn', 'Michael Botsch', 'Wolfgang Utschick']\n",
      "Tóm tắt:\n",
      "Abstract:  For automotive applications, the Graph Attention Network (GAT) is a\n",
      "prominently used architecture to include relational information of a traffic\n",
      "scenario during feature embedding. As shown in this work, however, one of the\n",
      "most popular GAT realizations, namely GATv2, has potential pitfalls that hinder\n",
      "an optimal parameter learning. Especially for small and sparse graph structures\n",
      "a proper optimization is problematic. To surpass limitations, this work\n",
      "proposes architectural modifications of GATv2. In controlled experiments, it is\n",
      "shown that the proposed model adaptions improve prediction performance in a\n",
      "node-level regression task and make it more robust to parameter initialization.\n",
      "This work aims for a better understanding of the attention mechanism and\n",
      "analyzes its interpretability of identifying causal importance.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16196\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 24:\n",
      "Tên bài báo:\n",
      "Abstractive Summary Generation for the Urdu Language\n",
      "Tên tác giả:\n",
      "['Ali Raza', 'Hadia Sultan Raja', 'Usman Maratib']\n",
      "Tóm tắt:\n",
      "Abstract:  Abstractive summary generation is a challenging task that requires the model\n",
      "to comprehend the source text and generate a concise and coherent summary that\n",
      "captures the essential information. In this paper, we explore the use of an\n",
      "encoder/decoder approach for abstractive summary generation in the Urdu\n",
      "language. We employ a transformer-based model that utilizes self-attention\n",
      "mechanisms to encode the input text and generate a summary. Our experiments\n",
      "show that our model can produce summaries that are grammatically correct and\n",
      "semantically meaningful. We evaluate our model on a publicly available dataset\n",
      "and achieve state-of-the-art results in terms of Rouge scores. We also conduct\n",
      "a qualitative analysis of our model's output to assess its effectiveness and\n",
      "limitations. Our findings suggest that the encoder/decoder approach is a\n",
      "promising method for abstractive summary generation in Urdu and can be extended\n",
      "to other languages with suitable modifications.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16195\n",
      "_________________________________________________\n",
      "\n",
      "Bài báo số 25:\n",
      "Tên bài báo:\n",
      "Explainability Techniques for Chemical Language Models\n",
      "Tên tác giả:\n",
      "['Stefan Hödl', 'William Robinson', 'Yoram Bachrach', 'Wilhelm Huck', 'Tal Kachman']\n",
      "Tóm tắt:\n",
      "Abstract:  Explainability techniques are crucial in gaining insights into the reasons\n",
      "behind the predictions of deep learning models, which have not yet been applied\n",
      "to chemical language models. We propose an explainable AI technique that\n",
      "attributes the importance of individual atoms towards the predictions made by\n",
      "these models. Our method backpropagates the relevance information towards the\n",
      "chemical input string and visualizes the importance of individual atoms. We\n",
      "focus on self-attention Transformers operating on molecular string\n",
      "representations and leverage a pretrained encoder for finetuning. We showcase\n",
      "the method by predicting and visualizing solubility in water and organic\n",
      "solvents. We achieve competitive model performance while obtaining\n",
      "interpretable predictions, which we use to inspect the pretrained model.\n",
      "\n",
      "    \n",
      "Chủ đề:\n",
      "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Chemical Physics (physics.chem-ph)\n",
      "Download:\n",
      "https://arxiv.org/pdf/2305.16192\n",
      "_________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for i in range(0,len(links)):\n",
    "    k+=1\n",
    "    doc_name,author,abstract,subject,download=scrape_doc_data(links[i])\n",
    "    print(f\"Bài báo số {k}:\")\n",
    "    print(\"Tên bài báo:\")\n",
    "    print(doc_name)\n",
    "    print(\"Tên tác giả:\")\n",
    "    print(str(author))\n",
    "    print(\"Tóm tắt:\")\n",
    "    print(abstract)\n",
    "    print(\"Chủ đề:\")\n",
    "    print(subject)\n",
    "    print(\"Download:\")\n",
    "    print(download)\n",
    "    print(\"_________________________________________________\\n\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu 3. Lưu tất cả các thông tin trên của tất cả bài báo thành định dạng file .csv, vơi các column là: Title, Authors, Abstract, Subjects, DownloadUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "for i in range(0,len(links)):\n",
    "    doc_name,author,abstract,subject,download=scrape_doc_data(links[i])\n",
    "    data.append([doc_name, author, abstract, subject, download])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Subject</th>\n",
       "      <th>DownloadURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Voyager: An Open-Ended Embodied Agent with Lar...</td>\n",
       "      <td>[Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Ma...</td>\n",
       "      <td>Abstract:  We introduce Voyager, the first LLM...</td>\n",
       "      <td>Artificial Intelligence (cs.AI); Machine Learn...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UpMax: User partitioning for MaxSAT</td>\n",
       "      <td>[Pedro Orvalho, Vasco Manquinho, Ruben Martins]</td>\n",
       "      <td>Abstract:  It has been shown that Maximum Sati...</td>\n",
       "      <td>Artificial Intelligence (cs.AI); Logic in Comp...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Understanding the Capabilities of Large Langua...</td>\n",
       "      <td>[Vishal Pallagani, Bharath Muppasani, Keerthir...</td>\n",
       "      <td>Abstract:  Automated planning is concerned wit...</td>\n",
       "      <td>Artificial Intelligence (cs.AI)</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Diagnosis Algorithms for a Rotary Indexing M...</td>\n",
       "      <td>[Maria Krantz, Oliver Niggemann]</td>\n",
       "      <td>Abstract:  Rotary Indexing Machines (RIMs) are...</td>\n",
       "      <td>Artificial Intelligence (cs.AI)</td>\n",
       "      <td>https://arxiv.org/pdf/2305.15934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learning Assumption-based Argumentation Framew...</td>\n",
       "      <td>[Maurizio Proietti, Francesca Toni]</td>\n",
       "      <td>Abstract:  We propose a novel approach to logi...</td>\n",
       "      <td>Artificial Intelligence (cs.AI)</td>\n",
       "      <td>https://arxiv.org/pdf/2305.15921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>On the Planning Abilities of Large Language Mo...</td>\n",
       "      <td>[Karthik Valmeekam, Matthew Marquez, Sarath Sr...</td>\n",
       "      <td>Abstract:  Intrigued by the claims of emergent...</td>\n",
       "      <td>Artificial Intelligence (cs.AI)</td>\n",
       "      <td>https://arxiv.org/pdf/2305.15771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TransWorldNG: Traffic Simulation via Foundatio...</td>\n",
       "      <td>[Ding Wang, Xuhong Wang, Liang Chen, Shengyue ...</td>\n",
       "      <td>Abstract:  Traffic simulation is a crucial too...</td>\n",
       "      <td>Artificial Intelligence (cs.AI)</td>\n",
       "      <td>https://arxiv.org/pdf/2305.15743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Asking Before Action: Gather Information in Em...</td>\n",
       "      <td>[Xiaoyu Chen, Shenao Zhang, Pushi Zhang, Li Zh...</td>\n",
       "      <td>Abstract:  With strong capabilities of reasoni...</td>\n",
       "      <td>Artificial Intelligence (cs.AI)</td>\n",
       "      <td>https://arxiv.org/pdf/2305.15695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SPRING: GPT-4 Out-performs RL Algorithms by St...</td>\n",
       "      <td>[Yue Wu, So Yeon Min, Shrimai Prabhumoye, Yona...</td>\n",
       "      <td>Abstract:  Open-world survival games pose sign...</td>\n",
       "      <td>Artificial Intelligence (cs.AI); Machine Learn...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.15486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Referred by Multi-Modality: A Unified Temporal...</td>\n",
       "      <td>[Shilin Yan, Renrui Zhang, Ziyu Guo, Wenchao C...</td>\n",
       "      <td>Abstract:  Recently, video object segmentation...</td>\n",
       "      <td>Computer Vision and Pattern Recognition (cs.CV...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Parallel Sampling of Diffusion Models</td>\n",
       "      <td>[Andy Shih, Suneel Belkhale, Stefano Ermon, Do...</td>\n",
       "      <td>Abstract:  Diffusion models are powerful gener...</td>\n",
       "      <td>Machine Learning (cs.LG); Artificial Intellige...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UMat: Uncertainty-Aware Single Image High Reso...</td>\n",
       "      <td>[Carlos Rodriguez-Pardo, Henar Dominguez-Elvir...</td>\n",
       "      <td>Abstract:  We propose a learning-based method ...</td>\n",
       "      <td>Computer Vision and Pattern Recognition (cs.CV...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fine-Grained Complexity Analysis of Multi-Agen...</td>\n",
       "      <td>[Tzvika Geft]</td>\n",
       "      <td>Abstract:  Multi-Agent Path Finding (MAPF) is ...</td>\n",
       "      <td>Multiagent Systems (cs.MA); Artificial Intelli...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HAAV: Hierarchical Aggregation of Augmented Vi...</td>\n",
       "      <td>[Chia-Wen Kuo, Zsolt Kira]</td>\n",
       "      <td>Abstract:  A great deal of progress has been m...</td>\n",
       "      <td>Computer Vision and Pattern Recognition (cs.CV...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Diversify Your Vision Datasets with Automatic ...</td>\n",
       "      <td>[Lisa Dunlap, Alyssa Umino, Han Zhang, Jiezhi ...</td>\n",
       "      <td>Abstract:  Many fine-grained classification ta...</td>\n",
       "      <td>Computer Vision and Pattern Recognition (cs.CV...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CENSUS-HWR: a large training dataset for offli...</td>\n",
       "      <td>[Chetan Joshi, Lawry Sorenson, Ammon Wolfert, ...</td>\n",
       "      <td>Abstract:  Progress in Automated Handwriting R...</td>\n",
       "      <td>Computer Vision and Pattern Recognition (cs.CV...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Scaling Data-Constrained Language Models</td>\n",
       "      <td>[Niklas Muennighoff, Alexander M. Rush, Boaz B...</td>\n",
       "      <td>Abstract:  The current trend of scaling langua...</td>\n",
       "      <td>Computation and Language (cs.CL); Artificial I...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Unified Modeling of Multi-Talker Overlapped Sp...</td>\n",
       "      <td>[Lingwei Meng, Jiawen Kang, Mingyu Cui, Haibin...</td>\n",
       "      <td>Abstract:  Multi-talker overlapped speech pose...</td>\n",
       "      <td>Sound (cs.SD); Artificial Intelligence (cs.AI)...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Neural Natural Language Processing for Long Te...</td>\n",
       "      <td>[Dimitrios Tsirmpas, Ioannis Gkionis, Ioannis ...</td>\n",
       "      <td>Abstract:  The adoption of Deep Neural Network...</td>\n",
       "      <td>Computation and Language (cs.CL); Artificial I...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fast Online Node Labeling for Very Large Graphs</td>\n",
       "      <td>[Baojian Zhou, Yifan Sun, Reza Babanezhad]</td>\n",
       "      <td>Abstract:  This paper studies the online node ...</td>\n",
       "      <td>Machine Learning (cs.LG); Artificial Intellige...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C-MCTS: Safe Planning with Monte Carlo Tree Se...</td>\n",
       "      <td>[Dinesh Parthasarathy, Georgios Kontes, Axel P...</td>\n",
       "      <td>Abstract:  Many real-world decision-making tas...</td>\n",
       "      <td>Machine Learning (cs.LG); Artificial Intellige...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>On Computing Universal Plans for Partially Obs...</td>\n",
       "      <td>[Fengming Zhu, Fangzhen Lin]</td>\n",
       "      <td>Abstract:  Multi-agent routing problems have d...</td>\n",
       "      <td>Multiagent Systems (cs.MA); Artificial Intelli...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Optimization and Interpretability of Graph Att...</td>\n",
       "      <td>[Marion Neumeier, Andreas Tollkühn, Sebastian ...</td>\n",
       "      <td>Abstract:  For automotive applications, the Gr...</td>\n",
       "      <td>Machine Learning (cs.LG); Artificial Intellige...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Abstractive Summary Generation for the Urdu La...</td>\n",
       "      <td>[Ali Raza, Hadia Sultan Raja, Usman Maratib]</td>\n",
       "      <td>Abstract:  Abstractive summary generation is a...</td>\n",
       "      <td>Computation and Language (cs.CL); Artificial I...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Explainability Techniques for Chemical Languag...</td>\n",
       "      <td>[Stefan Hödl, William Robinson, Yoram Bachrach...</td>\n",
       "      <td>Abstract:  Explainability techniques are cruci...</td>\n",
       "      <td>Machine Learning (cs.LG); Artificial Intellige...</td>\n",
       "      <td>https://arxiv.org/pdf/2305.16192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0   Voyager: An Open-Ended Embodied Agent with Lar...   \n",
       "1                 UpMax: User partitioning for MaxSAT   \n",
       "2   Understanding the Capabilities of Large Langua...   \n",
       "3   A Diagnosis Algorithms for a Rotary Indexing M...   \n",
       "4   Learning Assumption-based Argumentation Framew...   \n",
       "5   On the Planning Abilities of Large Language Mo...   \n",
       "6   TransWorldNG: Traffic Simulation via Foundatio...   \n",
       "7   Asking Before Action: Gather Information in Em...   \n",
       "8   SPRING: GPT-4 Out-performs RL Algorithms by St...   \n",
       "9   Referred by Multi-Modality: A Unified Temporal...   \n",
       "10              Parallel Sampling of Diffusion Models   \n",
       "11  UMat: Uncertainty-Aware Single Image High Reso...   \n",
       "12  Fine-Grained Complexity Analysis of Multi-Agen...   \n",
       "13  HAAV: Hierarchical Aggregation of Augmented Vi...   \n",
       "14  Diversify Your Vision Datasets with Automatic ...   \n",
       "15  CENSUS-HWR: a large training dataset for offli...   \n",
       "16           Scaling Data-Constrained Language Models   \n",
       "17  Unified Modeling of Multi-Talker Overlapped Sp...   \n",
       "18  Neural Natural Language Processing for Long Te...   \n",
       "19    Fast Online Node Labeling for Very Large Graphs   \n",
       "20  C-MCTS: Safe Planning with Monte Carlo Tree Se...   \n",
       "21  On Computing Universal Plans for Partially Obs...   \n",
       "22  Optimization and Interpretability of Graph Att...   \n",
       "23  Abstractive Summary Generation for the Urdu La...   \n",
       "24  Explainability Techniques for Chemical Languag...   \n",
       "\n",
       "                                              Authors  \\\n",
       "0   [Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Ma...   \n",
       "1     [Pedro Orvalho, Vasco Manquinho, Ruben Martins]   \n",
       "2   [Vishal Pallagani, Bharath Muppasani, Keerthir...   \n",
       "3                    [Maria Krantz, Oliver Niggemann]   \n",
       "4                 [Maurizio Proietti, Francesca Toni]   \n",
       "5   [Karthik Valmeekam, Matthew Marquez, Sarath Sr...   \n",
       "6   [Ding Wang, Xuhong Wang, Liang Chen, Shengyue ...   \n",
       "7   [Xiaoyu Chen, Shenao Zhang, Pushi Zhang, Li Zh...   \n",
       "8   [Yue Wu, So Yeon Min, Shrimai Prabhumoye, Yona...   \n",
       "9   [Shilin Yan, Renrui Zhang, Ziyu Guo, Wenchao C...   \n",
       "10  [Andy Shih, Suneel Belkhale, Stefano Ermon, Do...   \n",
       "11  [Carlos Rodriguez-Pardo, Henar Dominguez-Elvir...   \n",
       "12                                      [Tzvika Geft]   \n",
       "13                         [Chia-Wen Kuo, Zsolt Kira]   \n",
       "14  [Lisa Dunlap, Alyssa Umino, Han Zhang, Jiezhi ...   \n",
       "15  [Chetan Joshi, Lawry Sorenson, Ammon Wolfert, ...   \n",
       "16  [Niklas Muennighoff, Alexander M. Rush, Boaz B...   \n",
       "17  [Lingwei Meng, Jiawen Kang, Mingyu Cui, Haibin...   \n",
       "18  [Dimitrios Tsirmpas, Ioannis Gkionis, Ioannis ...   \n",
       "19         [Baojian Zhou, Yifan Sun, Reza Babanezhad]   \n",
       "20  [Dinesh Parthasarathy, Georgios Kontes, Axel P...   \n",
       "21                       [Fengming Zhu, Fangzhen Lin]   \n",
       "22  [Marion Neumeier, Andreas Tollkühn, Sebastian ...   \n",
       "23       [Ali Raza, Hadia Sultan Raja, Usman Maratib]   \n",
       "24  [Stefan Hödl, William Robinson, Yoram Bachrach...   \n",
       "\n",
       "                                             Abstract  \\\n",
       "0   Abstract:  We introduce Voyager, the first LLM...   \n",
       "1   Abstract:  It has been shown that Maximum Sati...   \n",
       "2   Abstract:  Automated planning is concerned wit...   \n",
       "3   Abstract:  Rotary Indexing Machines (RIMs) are...   \n",
       "4   Abstract:  We propose a novel approach to logi...   \n",
       "5   Abstract:  Intrigued by the claims of emergent...   \n",
       "6   Abstract:  Traffic simulation is a crucial too...   \n",
       "7   Abstract:  With strong capabilities of reasoni...   \n",
       "8   Abstract:  Open-world survival games pose sign...   \n",
       "9   Abstract:  Recently, video object segmentation...   \n",
       "10  Abstract:  Diffusion models are powerful gener...   \n",
       "11  Abstract:  We propose a learning-based method ...   \n",
       "12  Abstract:  Multi-Agent Path Finding (MAPF) is ...   \n",
       "13  Abstract:  A great deal of progress has been m...   \n",
       "14  Abstract:  Many fine-grained classification ta...   \n",
       "15  Abstract:  Progress in Automated Handwriting R...   \n",
       "16  Abstract:  The current trend of scaling langua...   \n",
       "17  Abstract:  Multi-talker overlapped speech pose...   \n",
       "18  Abstract:  The adoption of Deep Neural Network...   \n",
       "19  Abstract:  This paper studies the online node ...   \n",
       "20  Abstract:  Many real-world decision-making tas...   \n",
       "21  Abstract:  Multi-agent routing problems have d...   \n",
       "22  Abstract:  For automotive applications, the Gr...   \n",
       "23  Abstract:  Abstractive summary generation is a...   \n",
       "24  Abstract:  Explainability techniques are cruci...   \n",
       "\n",
       "                                              Subject  \\\n",
       "0   Artificial Intelligence (cs.AI); Machine Learn...   \n",
       "1   Artificial Intelligence (cs.AI); Logic in Comp...   \n",
       "2                     Artificial Intelligence (cs.AI)   \n",
       "3                     Artificial Intelligence (cs.AI)   \n",
       "4                     Artificial Intelligence (cs.AI)   \n",
       "5                     Artificial Intelligence (cs.AI)   \n",
       "6                     Artificial Intelligence (cs.AI)   \n",
       "7                     Artificial Intelligence (cs.AI)   \n",
       "8   Artificial Intelligence (cs.AI); Machine Learn...   \n",
       "9   Computer Vision and Pattern Recognition (cs.CV...   \n",
       "10  Machine Learning (cs.LG); Artificial Intellige...   \n",
       "11  Computer Vision and Pattern Recognition (cs.CV...   \n",
       "12  Multiagent Systems (cs.MA); Artificial Intelli...   \n",
       "13  Computer Vision and Pattern Recognition (cs.CV...   \n",
       "14  Computer Vision and Pattern Recognition (cs.CV...   \n",
       "15  Computer Vision and Pattern Recognition (cs.CV...   \n",
       "16  Computation and Language (cs.CL); Artificial I...   \n",
       "17  Sound (cs.SD); Artificial Intelligence (cs.AI)...   \n",
       "18  Computation and Language (cs.CL); Artificial I...   \n",
       "19  Machine Learning (cs.LG); Artificial Intellige...   \n",
       "20  Machine Learning (cs.LG); Artificial Intellige...   \n",
       "21  Multiagent Systems (cs.MA); Artificial Intelli...   \n",
       "22  Machine Learning (cs.LG); Artificial Intellige...   \n",
       "23  Computation and Language (cs.CL); Artificial I...   \n",
       "24  Machine Learning (cs.LG); Artificial Intellige...   \n",
       "\n",
       "                         DownloadURL  \n",
       "0   https://arxiv.org/pdf/2305.16291  \n",
       "1   https://arxiv.org/pdf/2305.16191  \n",
       "2   https://arxiv.org/pdf/2305.16151  \n",
       "3   https://arxiv.org/pdf/2305.15934  \n",
       "4   https://arxiv.org/pdf/2305.15921  \n",
       "5   https://arxiv.org/pdf/2305.15771  \n",
       "6   https://arxiv.org/pdf/2305.15743  \n",
       "7   https://arxiv.org/pdf/2305.15695  \n",
       "8   https://arxiv.org/pdf/2305.15486  \n",
       "9   https://arxiv.org/pdf/2305.16318  \n",
       "10  https://arxiv.org/pdf/2305.16317  \n",
       "11  https://arxiv.org/pdf/2305.16312  \n",
       "12  https://arxiv.org/pdf/2305.16303  \n",
       "13  https://arxiv.org/pdf/2305.16295  \n",
       "14  https://arxiv.org/pdf/2305.16289  \n",
       "15  https://arxiv.org/pdf/2305.16275  \n",
       "16  https://arxiv.org/pdf/2305.16264  \n",
       "17  https://arxiv.org/pdf/2305.16263  \n",
       "18  https://arxiv.org/pdf/2305.16259  \n",
       "19  https://arxiv.org/pdf/2305.16257  \n",
       "20  https://arxiv.org/pdf/2305.16209  \n",
       "21  https://arxiv.org/pdf/2305.16203  \n",
       "22  https://arxiv.org/pdf/2305.16196  \n",
       "23  https://arxiv.org/pdf/2305.16195  \n",
       "24  https://arxiv.org/pdf/2305.16192  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data, columns=['Title', 'Authors', 'Abstract', 'Subject', 'DownloadURL'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"ScienceDocs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
